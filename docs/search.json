[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYC3470Blog",
    "section": "",
    "text": "Final Project\n\n\n\n\n\n\n\nFinal Project\n\n\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 12: Customizations\n\n\n\n\n\n\n\nCustomizations\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 13: Slide Decks\n\n\n\n\n\n\n\nQuarto\n\n\nSlides\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nTidy Tuesday: Example\n\n\n\n\n\n\n\nData Tidying\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nTidy Tuesday: Example II\n\n\n\n\n\n\n\nData Tidying\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 11: Data Wrangling\n\n\n\n\n\n\n\nData Wrangling\n\n\n\n\n\n\n\n\n\n\n\nApr 24, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 10: Data Tidying\n\n\n\n\n\n\n\nData Tidying\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 8: Data Relations\n\n\n\n\n\n\n\nData Relations\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nMidterm: Part II\n\n\n\n\n\n\n\nMidterm\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nVideo Game Review Report\n\n\n\n\n\n\n\nData Report\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nMidterm: Part I\n\n\n\n\n\n\n\nMidterm\n\n\n\n\n\n\n\n\n\n\n\nMar 15, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 6: Data Summaries\n\n\n\n\n\n\n\nData Summaries\n\n\n\n\n\n\n\n\n\n\n\nMar 15, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 7: More ggplot2\n\n\n\n\n\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 5: Data Import\n\n\n\n\n\n\n\nData Import\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 4: Data Visualization\n\n\n\n\n\n\n\nData Types\n\n\nTidy Data\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 5a: Loops & Logic\n\n\n\n\n\n\n\nLoops\n\n\nLogic\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nWeek 3: Qmd Skills\n\n\n\n\n\n\n\nQmd Experiment\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nNew Post Test\n\n\n\n\n\n\n\nnew\n\n\ntesting\n\n\nconfused\n\n\n\n\n\n\n\n\n\n\n\nJan 28, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\n  \n\n\n\n\nMy Tip Sheet for Week 2\n\n\n\n\n\n\n\ntips\n\n\n\n\n\n\n\n\n\n\n\nJan 25, 2023\n\n\nGabi Yepez\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/final-project/index.html",
    "href": "posts/final-project/index.html",
    "title": "Final Project",
    "section": "",
    "text": "The lab study uses open data from Experiment 1 of Mehr, Song, and Spelke (2016). This is a reproduction of the results found in their paper. The experiment asks ‘Does music convey social information to infants?’. Different infants may grow up in different cultures and thus, the songs they are exposed to will differ. Following this pattern, when someone new sings a familiar song to an infant, it may signal that this person is part of their social group (Mehr et al., 2016).\n\n\n\nhttps://journals.sagepub.com/stoken/default+domain/d5HcBHg85XamSXGdYqYN/full\nhttps://raw.githubusercontent.com/CrumpLab/statisticsLab/master/data/MehrSongSpelke2016.csv\n\n\n\nlibrary(data.table) #loads data table library\n\nall_data <- fread(\"https://raw.githubusercontent.com/CrumpLab/statisticsLab/master/data/MehrSongSpelke2016.csv\") #loaded data via web address, easier than downloading data file\n\n\nlibrary(summarytools) #use to summarize all data\nview(dfSummary(all_data)) #will show summary of all data\n\nSwitching method to 'browser'\n\n\nOutput file written: C:\\Users\\gabiy\\AppData\\Local\\Temp\\RtmpCAPOs2\\file33ec57f82945.html\n\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:data.table':\n\n    between, first, last\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nexperiment_one <- all_data %>% filter(exp1==1) #filtering data to reduce rows into a new variable\n\n\n\n\n\n#data from trials to show infant looking behavior didn't change due to chance\nbaseline <- experiment_one$Baseline_Proportion_Gaze_to_Singer\n\n\n#looking at numbers, shows all data point for each infant as dot\nplot(baseline)\n\n\n\n\n\n#hist to show frequency proportions better\nhist(baseline)\n\n\n\n\n\n\n\n\n#mean and standard deviation for sample\nmean(baseline)\n\n[1] 0.5210967\n\nsd(baseline)\n\n[1] 0.1769651\n\n\n\n\n\n\nt.test(baseline, mu=.5) #reported as \"t(31) = .67, p = .505.\"\n\n\n    One Sample t-test\n\ndata:  baseline\nt = 0.67438, df = 31, p-value = 0.5051\nalternative hypothesis: true mean is not equal to 0.5\n95 percent confidence interval:\n 0.4572940 0.5848994\nsample estimates:\nmean of x \n0.5210967 \n\n\n\n\n\n\ntest_phase <- experiment_one$Test_Proportion_Gaze_to_Singer\n\nplot(test_phase)\n\n\n\n\n\nhist(test_phase)\n\n\n\n\n\nmean(test_phase)\n\n[1] 0.5934913\n\n## [1] 0.5934913\n\nsd(test_phase)\n\n[1] 0.1786884\n\n## [1] 0.1786884\n\nt.test(test_phase, mu = .5)\n\n\n    One Sample t-test\n\ndata:  test_phase\nt = 2.9597, df = 31, p-value = 0.005856\nalternative hypothesis: true mean is not equal to 0.5\n95 percent confidence interval:\n 0.5290672 0.6579153\nsample estimates:\nmean of x \n0.5934913 \n\n\n\n\n\n\nt.test(test_phase, baseline, paired=TRUE, var.equal=TRUE)\n\n\n    Paired t-test\n\ndata:  test_phase and baseline\nt = 2.4164, df = 31, p-value = 0.02175\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.01129217 0.13349698\nsample estimates:\nmean difference \n     0.07239458 \n\n\n\nt.test(test_phase, baseline, paired=TRUE, var.equal=TRUE)\n\n\n    Paired t-test\n\ndata:  test_phase and baseline\nt = 2.4164, df = 31, p-value = 0.02175\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.01129217 0.13349698\nsample estimates:\nmean difference \n     0.07239458 \n\ndifference_scores<-test_phase-baseline\n\nt.test(difference_scores, mu=0)\n\n\n    One Sample t-test\n\ndata:  difference_scores\nt = 2.4164, df = 31, p-value = 0.02175\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.01129217 0.13349698\nsample estimates:\n mean of x \n0.07239458 \n\n\n\n\n\n\ndifference_scores <- test_phase-baseline\n\nlength(difference_scores[difference_scores>0])\n\n[1] 22\n\n\n\n\n\n\n#creating dataframe for plotting\nPhase <- rep(c(\"Baseline\",\"Test\"), each = 32)\n\nProportions <- c(baseline,test_phase)\n\nplot_df <- data.frame(Phase,Proportions)\n\nplot_df\n\n      Phase Proportions\n1  Baseline   0.4371257\n2  Baseline   0.4125326\n3  Baseline   0.7544910\n4  Baseline   0.4388778\n5  Baseline   0.4746450\n6  Baseline   0.8709016\n7  Baseline   0.2367150\n8  Baseline   0.7592593\n9  Baseline   0.4163347\n10 Baseline   0.7995338\n11 Baseline   0.3786765\n12 Baseline   0.6978922\n13 Baseline   0.5934066\n14 Baseline   0.6149068\n15 Baseline   0.6149068\n16 Baseline   0.3168317\n17 Baseline   0.3104167\n18 Baseline   0.5043668\n19 Baseline   0.4693396\n20 Baseline   0.5040816\n21 Baseline   0.5640327\n22 Baseline   0.2566372\n23 Baseline   0.7000000\n24 Baseline   0.3823529\n25 Baseline   0.3718593\n26 Baseline   0.2844639\n27 Baseline   0.7678161\n28 Baseline   0.4737864\n29 Baseline   0.8212181\n30 Baseline   0.5901639\n31 Baseline   0.4220374\n32 Baseline   0.4354839\n33     Test   0.6027398\n34     Test   0.6830266\n35     Test   0.7241379\n36     Test   0.2816538\n37     Test   0.4985423\n38     Test   0.9509202\n39     Test   0.4177546\n40     Test   0.9382023\n41     Test   0.5000000\n42     Test   0.5862944\n43     Test   0.4726225\n44     Test   0.5083799\n45     Test   0.8111888\n46     Test   0.5718015\n47     Test   0.7774481\n48     Test   0.2628458\n49     Test   0.5079365\n50     Test   0.4369748\n51     Test   0.5421053\n52     Test   0.6008968\n53     Test   0.4186747\n54     Test   0.7894737\n55     Test   0.7601078\n56     Test   0.6238938\n57     Test   0.3664122\n58     Test   0.4615385\n59     Test   0.8995215\n60     Test   0.5311005\n61     Test   0.5418994\n62     Test   0.7003891\n63     Test   0.7629629\n64     Test   0.4602740\n\n\n\n\n\n\nlibrary(ggplot2)\n\nggplot(plot_df, aes(x=Phase, y=Proportions))+\n  geom_point()\n\n\n\n\n\n\n\n\nmean_df <- aggregate(Proportions ~ Phase, plot_df, mean)\n\n\nggplot(plot_df, aes(x=Phase, y=Proportions))+ \n  geom_point()+\n  geom_point(data=mean_df, color=\"Red\", size=2)\n\n\n\n\n\n\n\n\nggplot(plot_df, aes(x=Phase, y=Proportions))+ \n  geom_point()+\n  geom_bar(data=mean_df, stat=\"identity\",aes(fill=Phase))\n\n\n\n\n\nggplot(plot_df, aes(x=Phase, y=Proportions))+ \n  geom_bar(data=mean_df, stat=\"identity\",aes(fill=Phase))+\n  geom_point()\n\n\n\n\n\n\n\n\ndifference_scores <- baseline-test_phase #calculate difference scores\n\nstandard_error <- sd(difference_scores)/sqrt(length(difference_scores)) #calculate SEM\n\n\nggplot(plot_df, aes(x=Phase, y=Proportions))+ \n  geom_bar(data=mean_df, stat=\"identity\",aes(fill=Phase))+\n  geom_errorbar(data=mean_df, aes(ymin=Proportions-standard_error, \n                                  ymax=Proportions+standard_error), width=.1) +\n  geom_point(alpha=.25)\n\n\n\n\n\ndifference_scores <- test_phase-baseline #calculate difference scores\n\nstandard_error <- sd(difference_scores)/sqrt(length(difference_scores)) #calculate SEM\n\nmean_difference <- mean(difference_scores)\n\nqplot(x=\"MeanDifference\", y=mean_difference)+\n  geom_bar(stat=\"identity\", width=.5, alpha=.5)+\n  geom_hline(yintercept=0)+\n  geom_point(aes(y=difference_scores), alpha=.25)+\n  geom_errorbar(aes(ymin=mean_difference-standard_error, \n                                  ymax=mean_difference+standard_error), width=.1)\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\n\n\nt_test_results <- t.test(difference_scores)\n\nlower_interval<- t_test_results$conf.int[1]\n\nupper_interval<- t_test_results$conf.int[2]\n\n\nqplot(x=\"MeanDifference\", y=mean_difference)+\n  geom_bar(stat=\"identity\", width=.5, alpha=.5)+\n  geom_hline(yintercept=0)+\n  geom_point(aes(y=difference_scores), alpha=.25)+\n  geom_errorbar(aes(ymin=lower_interval, \n                                  ymax=upper_interval), width=.1)\n\n\n\n\n\n\n\n\nsample_sd   <- (sd(baseline)+sd(test_phase))/2\n\nsimulated_means <- length(1000)\nfor(i in 1:1000){\n simulated_means[i] <- mean(rnorm(32,.5, sample_sd))\n}\n\nhist(simulated_means)\n\n\n\n\n\n#simulation of mean difference\n\nsample_sd   <- sd(baseline-test_phase)\n\nsimulated_mean_difference <- length(1000)\nfor(i in 1:1000){\n simulated_mean_difference[i] <- mean(rnorm(32,0, sample_sd))\n}\n\nhist(simulated_mean_difference)\n\n\n\n\n\n\n\n\nMehr, S. A., Song. L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27, 486-501.\nCrump, M. J.C., Krishnan, A., Volz, S., Chavarga, A. (2018). Answering questions with data: Lab Manual.\nhttps://crumplab.com/statisticsLab/lab-6-t-test-one-sample-paired-sample.html#excel-6\nhttps://journals.sagepub.com/stoken/default+domain/d5HcBHg85XamSXGdYqYN/full"
  },
  {
    "objectID": "posts/new-post-test/index.html",
    "href": "posts/new-post-test/index.html",
    "title": "New Post Test",
    "section": "",
    "text": "Testing - following the tutorial, but not sure how to remove the old image, trying to put a new one. I also kept the original code that was in the copied post, but changed some numbers - also not sure how that works.\nUpdate - I didn’t know how to put the image in and it wasn’t working for a while. However, something I did made it show up now woo!\n\n1000 - 7\n\n[1] 993"
  },
  {
    "objectID": "posts/part 2/index.html",
    "href": "posts/part 2/index.html",
    "title": "Midterm part 2",
    "section": "",
    "text": "Do simple math with numbers, addition, subtraction, multiplication, division\n\n\n1+1\n\n[1] 2\n\n3-4\n\n[1] -1\n\n4*4\n\n[1] 16\n\n10/2\n\n[1] 5\n\n\n\n\n\n\nPut numbers into variables, do simple math on the variables\n\n\na<-1\nb<-2\nc<-3\n\n(a+b) / c\n\n[1] 1\n\n\n\n\n\n\nWrite code that will place the numbers 1 to 100 separately into a variable using for loop. Then, again using the seq function.\n\n\nsolution <- 1:100\n\na <- c()\n\nfor(i in 1:100) {\n  a[i] <- i\n}\na\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\ni <- 0\na <- c()\nwhile(i <= 100) {\n  i <- i+1\n  a[i] <- i\n}\n\na\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101\n\n\n\n\n\n\nWrite a function to find the sum of all integers between any two values\n\n\nsum(50:100) # easy way but have to write function to find it\n\n[1] 3825\n\n# function syntax\nsum_sequence <- function(min,max){\n  return(sum(min:max))\n}\n\nsum_sequence(min=5, max=100)\n\n[1] 5040\n\nsum_sequence_loop <- function(min,max){\n  a <- 0\n   for(i in min:max){\n    a <- a+i\n   }\n  return(a)\n}\n\n\n\n\n\nList all of the prime numbers from 1 to 1000\n\n\na <- 1:1000\n\nisprime <- function(x) {\n  generate_sequence <- 1:x\n  counter <- 0\n  for(i in generate_sequence){\n    if(x%%i == 0){\n      counter <- counter+1\n    }\n  }\n  \n  if(counter <= 2) {\n    return(TRUE)\n  } else{\n    return(FALSE)\n  }\n}\n\nfor(i in a){\n  if(isprime(i) == TRUE) print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 5\n[1] 7\n[1] 11\n[1] 13\n[1] 17\n[1] 19\n[1] 23\n[1] 29\n[1] 31\n[1] 37\n[1] 41\n[1] 43\n[1] 47\n[1] 53\n[1] 59\n[1] 61\n[1] 67\n[1] 71\n[1] 73\n[1] 79\n[1] 83\n[1] 89\n[1] 97\n[1] 101\n[1] 103\n[1] 107\n[1] 109\n[1] 113\n[1] 127\n[1] 131\n[1] 137\n[1] 139\n[1] 149\n[1] 151\n[1] 157\n[1] 163\n[1] 167\n[1] 173\n[1] 179\n[1] 181\n[1] 191\n[1] 193\n[1] 197\n[1] 199\n[1] 211\n[1] 223\n[1] 227\n[1] 229\n[1] 233\n[1] 239\n[1] 241\n[1] 251\n[1] 257\n[1] 263\n[1] 269\n[1] 271\n[1] 277\n[1] 281\n[1] 283\n[1] 293\n[1] 307\n[1] 311\n[1] 313\n[1] 317\n[1] 331\n[1] 337\n[1] 347\n[1] 349\n[1] 353\n[1] 359\n[1] 367\n[1] 373\n[1] 379\n[1] 383\n[1] 389\n[1] 397\n[1] 401\n[1] 409\n[1] 419\n[1] 421\n[1] 431\n[1] 433\n[1] 439\n[1] 443\n[1] 449\n[1] 457\n[1] 461\n[1] 463\n[1] 467\n[1] 479\n[1] 487\n[1] 491\n[1] 499\n[1] 503\n[1] 509\n[1] 521\n[1] 523\n[1] 541\n[1] 547\n[1] 557\n[1] 563\n[1] 569\n[1] 571\n[1] 577\n[1] 587\n[1] 593\n[1] 599\n[1] 601\n[1] 607\n[1] 613\n[1] 617\n[1] 619\n[1] 631\n[1] 641\n[1] 643\n[1] 647\n[1] 653\n[1] 659\n[1] 661\n[1] 673\n[1] 677\n[1] 683\n[1] 691\n[1] 701\n[1] 709\n[1] 719\n[1] 727\n[1] 733\n[1] 739\n[1] 743\n[1] 751\n[1] 757\n[1] 761\n[1] 769\n[1] 773\n[1] 787\n[1] 797\n[1] 809\n[1] 811\n[1] 821\n[1] 823\n[1] 827\n[1] 829\n[1] 839\n[1] 853\n[1] 857\n[1] 859\n[1] 863\n[1] 877\n[1] 881\n[1] 883\n[1] 887\n[1] 907\n[1] 911\n[1] 919\n[1] 929\n[1] 937\n[1] 941\n[1] 947\n[1] 953\n[1] 967\n[1] 971\n[1] 977\n[1] 983\n[1] 991\n[1] 997\n\n\n\n\n\n\nGenerate 100 random numbers within a specific range\n\n\nrunif(100,0,100)\n\n  [1] 38.4460402 18.8109610 81.4764684  5.9846350 47.5998659  0.5002947\n  [7] 58.8629854 24.3857950  8.8112542 24.4202507 73.1221106 15.9664839\n [13] 51.2393622 88.5001608 49.3644173 82.2441335 86.5604895 30.6692167\n [19] 78.9017979 49.9996889 34.5128218 99.5474071 70.4703591 94.3992064\n [25] 52.7719136 16.3864006 93.0940565 69.1515604 86.7646683 17.0932303\n [31] 39.3824297 47.3377307 45.9282081 27.6066296 65.2907881 85.8274328\n [37] 13.7077113 85.2031423 10.3178386 19.3744259 42.0550555 15.7518199\n [43] 16.5074873 51.5529221 77.8079883 10.9786431  8.7976851 99.0213323\n [49] 59.1460075 44.2164646 54.4548418 42.1205293  1.4002525 36.4343556\n [55] 35.5599088 84.8886137  8.2157600 82.6872953 45.1546091 92.1759529\n [61] 53.7526680  5.7502143 74.6439151 37.7606502 56.6826358 42.7893124\n [67] 88.6639115  8.0072669 28.5926506 97.7251843 73.1564247 91.1857953\n [73] 28.9698689 73.7019798 71.5824657 69.2111972 77.2937644 17.1498989\n [79] 66.2388874 62.1702486 47.5984443 11.0783448 48.8793500 16.2428285\n [85] 10.7575518 47.3800598  8.9071838 50.4350245 58.8094410 43.6822130\n [91] 95.6646716 86.4926978 65.9957021 44.9295191 73.4480157  3.3766167\n [97] 64.7449806 28.1723492 83.1551350 47.1781888\n\n\n\n\n\n\n## mean\n\nmean_B <- function(x){\n  temp_sum <- 0\n  temp_length <- 0\n  for(i in x){\n  temp_sum <- temp_sum+i\n  temp_length <- temp_length+1\n  }\n  \n  return(temp_sum/temp_length)\n}\n\n\n## mode \n\ne <- c(1,1,1,1,1,2,3,4,5)\n\nmy_unique <- function(x){\n  unique_number <- c()\n  counter <- 0\n  for(i in x){\n    \n    test_unique <- i == unique_number\n    if(sum(test_unique) > 0) {\n      counter <- counter+1\n      unique_number[counter] <- unique_number\n    }\n    \n    print(sum(test_unique))\n    \n  }\n  \n  return(unique_number)\n}\n\n\n\n\n\n\n\n\n\n\n# Define the range of numbers\nnumbers <- 1:100\n\n# Loop through each number in the range\nfor (i in numbers) {\n  \n  # If the number is divisible by 3 and 5, print \"FizzBuzz\"\n  if (i %% 3 == 0 & i %% 5 == 0) {\n    print(\"FizzBuzz\")\n    \n  # If the number is divisible by 3, print \"Fizz\"\n  } else if (i %% 3 == 0) {\n    print(\"Fizz\")\n    \n  # If the number is divisible by 5, print \"Buzz\"\n  } else if (i %% 5 == 0) {\n    print(\"Buzz\")\n    \n  # Otherwise, print the number itself\n  } else {\n    print(i)\n  }\n}\n\n[1] 1\n[1] 2\n[1] \"Fizz\"\n[1] 4\n[1] \"Buzz\"\n[1] \"Fizz\"\n[1] 7\n[1] 8\n[1] \"Fizz\"\n[1] \"Buzz\"\n[1] 11\n[1] \"Fizz\"\n[1] 13\n[1] 14\n[1] \"FizzBuzz\"\n[1] 16\n[1] 17\n[1] \"Fizz\"\n[1] 19\n[1] \"Buzz\"\n[1] \"Fizz\"\n[1] 22\n[1] 23\n[1] \"Fizz\"\n[1] \"Buzz\"\n[1] 26\n[1] \"Fizz\"\n[1] 28\n[1] 29\n[1] \"FizzBuzz\"\n[1] 31\n[1] 32\n[1] \"Fizz\"\n[1] 34\n[1] \"Buzz\"\n[1] \"Fizz\"\n[1] 37\n[1] 38\n[1] \"Fizz\"\n[1] \"Buzz\"\n[1] 41\n[1] \"Fizz\"\n[1] 43\n[1] 44\n[1] \"FizzBuzz\"\n[1] 46\n[1] 47\n[1] \"Fizz\"\n[1] 49\n[1] \"Buzz\"\n[1] \"Fizz\"\n[1] 52\n[1] 53\n[1] \"Fizz\"\n[1] \"Buzz\"\n[1] 56\n[1] \"Fizz\"\n[1] 58\n[1] 59\n[1] \"FizzBuzz\"\n[1] 61\n[1] 62\n[1] \"Fizz\"\n[1] 64\n[1] \"Buzz\"\n[1] \"Fizz\"\n[1] 67\n[1] 68\n[1] \"Fizz\"\n[1] \"Buzz\"\n[1] 71\n[1] \"Fizz\"\n[1] 73\n[1] 74\n[1] \"FizzBuzz\"\n[1] 76\n[1] 77\n[1] \"Fizz\"\n[1] 79\n[1] \"Buzz\"\n[1] \"Fizz\"\n[1] 82\n[1] 83\n[1] \"Fizz\"\n[1] \"Buzz\"\n[1] 86\n[1] \"Fizz\"\n[1] 88\n[1] 89\n[1] \"FizzBuzz\"\n[1] 91\n[1] 92\n[1] \"Fizz\"\n[1] 94\n[1] \"Buzz\"\n[1] \"Fizz\"\n[1] 97\n[1] 98\n[1] \"Fizz\"\n[1] \"Buzz\"\n\n\n\n\n\n\n# set the number of dice rolls\nnum_rolls <- 100\n\n# simulate rolling a six-sided dice\ndice_rolls <- sample(1:6, num_rolls, replace = TRUE)\n\n# print the results\nprint(dice_rolls)\n\n  [1] 5 4 4 3 1 2 3 5 6 5 4 2 1 6 6 6 2 1 6 5 2 1 3 4 6 3 3 2 4 6 6 5 6 4 4 2 2\n [38] 2 5 5 2 3 3 6 1 3 3 2 3 4 3 4 1 2 3 1 5 2 6 5 4 2 6 5 4 2 3 2 4 3 6 2 1 4\n [75] 6 2 6 1 3 3 2 3 4 6 4 3 6 4 4 4 6 5 1 4 5 3 3 3 1 4\n\n\n\n\n\n\n# Set up the game board\ngame_board <- data.frame(\n  start = c(1, 4, 9, 16, 21, 28, 36, 44, 52, 67, 71, 80, 87),\n  end = c(38, 14, 31, 6, 42, 84, 44, 26, 72, 86, 91, 100, 24)\n)\n\n# Define a function to simulate a single turn\nsimulate_turn <- function(current_position) {\n  # Roll the dice\n  dice_roll <- sample(1:6, 1)\n\n  # Move the player\n  new_position <- current_position + dice_roll\n\n  # Check for a ladder or snake\n  ladder_or_snake <- which(game_board$start == new_position)\n  if (length(ladder_or_snake) > 0) {\n    new_position <- game_board$end[ladder_or_snake]\n    message(paste0(\"Landed on a ladder! Moving to position \", new_position, \".\"))\n  } else {\n    ladder_or_snake <- which(game_board$end == new_position)\n    if (length(ladder_or_snake) > 0) {\n      new_position <- game_board$start[ladder_or_snake]\n      message(paste0(\"Landed on a snake! Moving to position \", new_position, \".\"))\n    }\n  }\n\n  # Make sure the player didn't go past the end of the board\n  if (new_position > 100) {\n    new_position <- current_position\n  }\n\n  # Return the new position\n  return(new_position)\n}\n\n# Define a function to simulate a full game\nsimulate_game <- function() {\n  # Initialize the game\n  position <- 0\n  turns <- 0\n\n  # Loop until the player reaches the end of the board\n  while (position < 100) {\n    # Simulate a turn\n    position <- simulate_turn(position)\n    turns <- turns + 1\n\n    # Print the current position\n    message(paste0(\"Current position: \", position, \".\"))\n  }\n\n  # Print the number of turns it took to win\n  message(paste0(\"You won in \", turns, \" turns!\"))\n}\n\n# Run the game\nsimulate_game()\n\nCurrent position: 3.\n\n\nLanded on a snake! Moving to position 16.\n\n\nCurrent position: 16.\n\n\nCurrent position: 17.\n\n\nCurrent position: 20.\n\n\nCurrent position: 22.\n\n\nCurrent position: 23.\n\n\nCurrent position: 29.\n\n\nLanded on a snake! Moving to position 9.\n\n\nCurrent position: 9.\n\n\nCurrent position: 11.\n\n\nCurrent position: 12.\n\n\nLanded on a ladder! Moving to position 6.\n\n\nCurrent position: 6.\n\n\nCurrent position: 10.\n\n\nLanded on a snake! Moving to position 4.\n\n\nCurrent position: 4.\n\n\nCurrent position: 10.\n\n\nCurrent position: 13.\n\n\nLanded on a ladder! Moving to position 6.\n\n\nCurrent position: 6.\n\n\nCurrent position: 12.\n\n\nLanded on a ladder! Moving to position 6.\n\n\nCurrent position: 6.\n\n\nCurrent position: 8.\n\n\nLanded on a snake! Moving to position 4.\n\n\nCurrent position: 4.\n\n\nLanded on a ladder! Moving to position 31.\n\n\nCurrent position: 31.\n\n\nCurrent position: 35.\n\n\nCurrent position: 39.\n\n\nCurrent position: 40.\n\n\nCurrent position: 43.\n\n\nCurrent position: 47.\n\n\nCurrent position: 50.\n\n\nCurrent position: 54.\n\n\nCurrent position: 57.\n\n\nCurrent position: 60.\n\n\nCurrent position: 66.\n\n\nLanded on a snake! Moving to position 52.\n\n\nCurrent position: 52.\n\n\nCurrent position: 58.\n\n\nCurrent position: 60.\n\n\nCurrent position: 63.\n\n\nCurrent position: 64.\n\n\nCurrent position: 65.\n\n\nLanded on a ladder! Moving to position 86.\n\n\nCurrent position: 86.\n\n\nCurrent position: 88.\n\n\nCurrent position: 93.\n\n\nCurrent position: 99.\n\n\nLanded on a snake! Moving to position 80.\n\n\nCurrent position: 80.\n\n\nLanded on a snake! Moving to position 28.\n\n\nCurrent position: 28.\n\n\nLanded on a snake! Moving to position 9.\n\n\nCurrent position: 9.\n\n\nLanded on a snake! Moving to position 4.\n\n\nCurrent position: 4.\n\n\nCurrent position: 10.\n\n\nLanded on a snake! Moving to position 4.\n\n\nCurrent position: 4.\n\n\nCurrent position: 8.\n\n\nLanded on a ladder! Moving to position 31.\n\n\nCurrent position: 31.\n\n\nCurrent position: 35.\n\n\nCurrent position: 40.\n\n\nCurrent position: 41.\n\n\nCurrent position: 46.\n\n\nCurrent position: 50.\n\n\nLanded on a ladder! Moving to position 72.\n\n\nCurrent position: 72.\n\n\nCurrent position: 78.\n\n\nCurrent position: 79.\n\n\nLanded on a ladder! Moving to position 100.\n\n\nCurrent position: 100.\n\n\nYou won in 58 turns!"
  },
  {
    "objectID": "posts/tidy-tues-ex/index.html",
    "href": "posts/tidy-tues-ex/index.html",
    "title": "Tidy Tuesday: Example",
    "section": "",
    "text": "#run once, install package\n# remotes::install_github(\"nrennie/LondonMarathon\")\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n# load data sets\ndata(winners, package = \"LondonMarathon\")\ndata(london_marathon, package = \"LondonMarathon\")\n\n\n# london marathon plot\nlondon_plot <- london_marathon %>%\n  filter(Year < 2020) %>%\n  mutate(Year = factor(Year))\n\n\nggplot(\n  data = london_plot,\n  mapping = aes(y = Year)\n) +\n  geom_point(aes(x = Starters),\n    colour = \"#008080\"\n  ) +\n  geom_point(aes(x = Finishers),\n    colour = \"#800080\"\n  ) +\n  geom_segment(aes(\n    x = Starters,\n    xend = Finishers,\n    y = Year,\n    yend = Year\n  )) +\n  labs(\n    x = \"Number of runners\",\n    title = \"Number of London Marathon Starters and Finishers\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.title.y = element_blank(),\n    plot.background = element_rect(fill = \"white\", colour = \"white\"),\n    panel.background = element_rect(fill = \"white\", colour = \"white\")\n  )\n\n\n\n\n\nggsave(filename = \"london_marathon.png\", height = 7, width = 5)\n\n\n# winners plot\nwinners_plot <- winners %>%\n  group_by(Nationality) %>%\n  summarise(n = n())\n\nggplot(\n  data = winners_plot,\n  mapping = aes(\n    y = reorder(Nationality, n),\n    x = n\n  )\n) +\n  geom_col(fill = \"#e00601\") +\n  geom_text(aes(label = n),\n    colour = \"#e00601\",\n    hjust = -1\n  ) +\n  labs(\n    x = \"Number of winners\",\n    title = \"Nationality of London Marathon Winners\"\n  ) +\n  scale_x_continuous(limits = c(0, 50)) +\n  coord_cartesian(expand = FALSE) +\n  theme_minimal() +\n  theme(\n    axis.title.y = element_blank(),\n    plot.background = element_rect(fill = \"white\", colour = \"white\"),\n    panel.background = element_rect(fill = \"white\", colour = \"white\")\n  )\n\n\n\nggsave(filename = \"winners.png\", height = 7, width = 5)"
  },
  {
    "objectID": "posts/tidy-tues-ex2/index.html",
    "href": "posts/tidy-tues-ex2/index.html",
    "title": "Tidy Tuesday: Example II",
    "section": "",
    "text": "Tidy Tuesday - Example II\n\ntuesdata <- tidytuesdayR::tt_load('2023-05-02')\n\n--- Compiling #TidyTuesday Information for 2023-05-02 ----\n\n\n--- There are 3 files available ---\n\n\n--- Starting Download ---\n\n\n\n    Downloading file 1 of 3: `plots.csv`\n\n\nOnly 10 Github queries remaining until 2023-05-15 12:04:39 PM EDT.\n\n\n    Downloading file 2 of 3: `species.csv`\n\n\nOnly 9 Github queries remaining until 2023-05-15 12:04:39 PM EDT.\n\n\n    Downloading file 3 of 3: `surveys.csv`\n\n\nOnly 8 Github queries remaining until 2023-05-15 12:04:38 PM EDT.\n\n\n--- Download complete ---\n\ntuesdata <- tidytuesdayR::tt_load(2023, week = 18)\n\nOnly 7 Github queries remaining until 2023-05-15 12:04:39 PM EDT.\n\n\nOnly 7 Github queries remaining until 2023-05-15 12:04:39 PM EDT.\n\n\n--- Compiling #TidyTuesday Information for 2023-05-02 ----\n\n\nOnly 7 Github queries remaining until 2023-05-15 12:04:39 PM EDT.\n\n\n--- There are 3 files available ---\n\n\nOnly 6 Github queries remaining until 2023-05-15 12:04:38 PM EDT.\n\n\n--- Starting Download ---\n\n\nOnly 6 Github queries remaining until 2023-05-15 12:04:38 PM EDT.\n\n\n    Downloading file 1 of 3: `plots.csv`\n\n\nOnly 5 Github queries remaining until 2023-05-15 12:04:38 PM EDT.\n\n\n    Downloading file 2 of 3: `species.csv`\n\n\nOnly 4 Github queries remaining until 2023-05-15 12:04:39 PM EDT.\n\n\n    Downloading file 3 of 3: `surveys.csv`\n\n\nOnly 3 Github queries remaining until 2023-05-15 12:04:39 PM EDT.\n\n\n--- Download complete ---\n\n\n\nplots <- tuesdata$plots\nspecies <- tuesdata$species\nsurveys <- tuesdata$surveys\n\n\n# All packages used in this script:\nlibrary(portalr)\n\nWarning: package 'portalr' was built under R version 4.2.3\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndownload_observations(\".\")\n\nDownloading version `4.10.0` of the data...\n\n\nWarning in file.rename(file.path(path, temp_unzip), final): cannot rename file\n'./weecology-PortalData-a7debc6' to './PortalData', reason 'The system cannot\nfind the file specified'\n\ndata_tables <- load_rodent_data()\n\nLoading in data version 4.10.0\n\nspecies_data <- data_tables[[\"species_table\"]]\nplots_data <- data_tables[[\"plots_table\"]]\n\nplot_treatments <- plots_data %>%\n  filter(year > 1977) |>\n  mutate(iso_date = as.Date(paste0(year, \"-\", month, \"-\", \"01\")), \n         plot = as.factor(plot)) %>%\n  select(iso_date, plot, treatment)\n\nplots_data_longterm <- plot_treatments |>\n  group_by(plot) |>\n  summarize(treatment = case_when(\n              all(treatment == \"control\") ~ \"control\",\n              all(treatment == \"exclosure\") ~ \"exclosure\")) |>\n  filter(!is.na(treatment))\n\nspecies_data <- species_data |>\n  filter(censustarget == 1, unidentified == 0)\n\nsurvey_data <- summarize_individual_rodents(\n  time = \"date\",\n  length = \"Longterm\") |>\n  filter(year > 1977) |>\n  filter(species %in% unique(species_data$species))\n\nLoading in data version 4.10.0\n\nwrite.csv(survey_data, \"surveys.csv\", row.names = FALSE, na = \"\")\nwrite.csv(plots_data_longterm, \"plots.csv\", row.names = FALSE, na = \"\")\nwrite.csv(species_data, \"species.csv\", row.names = FALSE, na = \"\")"
  },
  {
    "objectID": "posts/tip-sheet/index.html",
    "href": "posts/tip-sheet/index.html",
    "title": "My Tip Sheet for Week 2",
    "section": "",
    "text": "Tips:\nHow to make new blog post:\n\nopen blog in Rstudio, find posts folder, copy post and save as new post name\n\nHow to commit and push changes to github:\n\nmake change, render website via Rstudio, commit in github desktop w/ commit msg, push to github.com"
  },
  {
    "objectID": "posts/week-10/index.html",
    "href": "posts/week-10/index.html",
    "title": "Week 10: Data Tidying",
    "section": "",
    "text": "Data Tidying\n\nlibrary(tidyverse) # for data wrangling\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\nuntidy_data <- read_csv(\"data/untidy_data.csv\", show_col_types = FALSE) #reads data and loads into environment via assign\n\n\ntidy_data <- read_csv(\"data/tidy_data.csv\", show_col_types = FALSE) #reads data and loads into environment via assign\n\n\n#way to show data in table\nknitr::kable(tidy_data)\n\n\n\n\ncustomer_id\nyear\nitems\nprice_per_item\ntotalprice\n\n\n\n\n1\n2018\n2\n3.91\n7.82\n\n\n1\n2019\n8\n4.72\n37.76\n\n\n1\n2020\n10\n5.59\n55.90\n\n\n2\n2018\n1\n3.91\n3.91\n\n\n2\n2019\n6\n4.72\n28.32\n\n\n2\n2020\n1\n5.59\n5.59\n\n\n3\n2018\n4\n3.91\n15.64\n\n\n3\n2019\n5\n4.72\n23.60\n\n\n3\n2020\n5\n5.59\n27.95\n\n\n4\n2018\n10\n3.91\n39.10\n\n\n4\n2019\n1\n4.72\n4.72\n\n\n4\n2020\n3\n5.59\n16.77\n\n\n5\n2018\n3\n3.91\n11.73\n\n\n5\n2019\n9\n4.72\n42.48\n\n\n5\n2020\n8\n5.59\n44.72\n\n\n\n\nknitr::kable(untidy_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncustomer_id\nitemsprice_2018\nitemsprice_2019\nitemsprice_2020\ntotalprice_2018\ntotalprice_2019\ntotalprice_2020\n\n\n\n\n1\n2 (3.91)\n8 (4.72)\n10 (5.59)\n7.82\n37.76\n55.90\n\n\n2\n1 (3.91)\n6 (4.72)\n1 (5.59)\n3.91\n28.32\n5.59\n\n\n3\n4 (3.91)\n5 (4.72)\n5 (5.59)\n15.64\n23.60\n27.95\n\n\n4\n10 (3.91)\n1 (4.72)\n3 (5.59)\n39.10\n4.72\n16.77\n\n\n5\n3 (3.91)\n9 (4.72)\n8 (5.59)\n11.73\n42.48\n44.72\n\n\n\n\n\n\ntidy_data %>%\n  group_by(customer_id) %>%\n  summarise(\n    total_items = sum(items),\n    total_price = sum(totalprice)\n  )\n\n# A tibble: 5 × 3\n  customer_id total_items total_price\n        <dbl>       <dbl>       <dbl>\n1           1          20       101. \n2           2           8        37.8\n3           3          14        67.2\n4           4          14        60.6\n5           5          20        98.9\n\n\n\n# select just the customer ID and 3 total price columns\nwide_totalprice <- select( #select allows to pick certain columns\n  .data = untidy_data,\n  customer_id, \n  `2018` = totalprice_2018,\n  `2019` = totalprice_2019,\n  `2020` = totalprice_2020\n)\n\nlong_totalprice <- pivot_longer(\n  data = wide_totalprice,\n  cols = `2018`:`2020`,\n  names_to = \"year\",\n  values_to = \"totalprice\")\n\nuntidy_data[,c(1,5:7)] #[] specifies which col/row to show\n\n# A tibble: 5 × 4\n  customer_id totalprice_2018 totalprice_2019 totalprice_2020\n        <dbl>           <dbl>           <dbl>           <dbl>\n1           1            7.82           37.8            55.9 \n2           2            3.91           28.3             5.59\n3           3           15.6            23.6            28.0 \n4           4           39.1             4.72           16.8 \n5           5           11.7            42.5            44.7 \n\n\n\nggplot(long_totalprice, aes(x = totalprice, fill = year)) +\n  geom_histogram(binwidth = 10, color = \"black\")\n\n\n\n\n\n\npivot wider\n\n#reshapes the data wider via customer id\nwide_by_customer <- pivot_wider( \n  data = long_totalprice,\n  id_cols = year, # identifying column(s)\n  names_from = customer_id, # the new column names\n  names_prefix = \"C_\", # prefix for new column names\n  values_from = totalprice # the new column values\n)\n\n#reshapes the data wider via years\nwide_by_year <- pivot_wider( #\n  data = long_totalprice,\n  id_cols = customer_id, # identifying column(s)\n  names_from = year, # the new column names\n  values_from = totalprice # the new column values\n)\n\n\n#reshapes data longer-wise\nlonger_data <- pivot_longer(\n  data = untidy_data, \n  cols = itemsprice_2018:totalprice_2020, # columns to make long \n  names_to = c(\"category\", \"year\"), # new column names for cols\n  names_sep = \"_\", # how to split cols into new columns\n  # names_pattern = \"(.*)_(.*)\", # alternative to names_sep\n  values_to = \"value\", # new column name for values\n  \n  # make sure new columns are the right data type\n  names_transform = list(year = as.integer),\n  values_transform = list(value = as.character) \n)\n\n#wider\nwider_data <- pivot_wider(\n  data = longer_data,\n  id_cols = c(customer_id, year),\n  names_from = category,\n  values_from = value\n)\n\n#splits the columns that had combined data, in to separate ones via indicators\nsplit_data <- separate(\n  data = wider_data, \n  col = itemsprice, # the column to split\n  into = c(\"items\", \"price_per_item\"), # the new columns to create\n  sep = \" \", # split col by space\n  remove = TRUE, # whether to remove to old col\n  convert = TRUE # whether to fix the data type of the new columns\n)\n\n#mutates data to get rid of awkward parenthesis in values\nmutated_data <- mutate(\n  .data = split_data,\n  price_per_item = stringr::str_replace_all(\n    string = price_per_item, \n    pattern = \"[()]\", \n    replacement = \"\"\n  )\n)\n\n# check the data types\nglimpse(mutated_data)\n\nRows: 15\nColumns: 5\n$ customer_id    <dbl> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5\n$ year           <int> 2018, 2019, 2020, 2018, 2019, 2020, 2018, 2019, 2020, 2…\n$ items          <int> 2, 8, 10, 1, 6, 1, 4, 5, 5, 10, 1, 3, 3, 9, 8\n$ price_per_item <chr> \"3.91\", \"4.72\", \"5.59\", \"3.91\", \"4.72\", \"5.59\", \"3.91\",…\n$ totalprice     <chr> \"7.82\", \"37.76\", \"55.9\", \"3.91\", \"28.32\", \"5.59\", \"15.6…\n\n\n\ntidy_data <- type_convert(\n  df = mutated_data,\n  trim_ws = TRUE # removes spaces before and after values\n)\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  price_per_item = col_double(),\n  totalprice = col_double()\n)\n\n# check the data types\nglimpse(tidy_data)\n\nRows: 15\nColumns: 5\n$ customer_id    <dbl> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5\n$ year           <int> 2018, 2019, 2020, 2018, 2019, 2020, 2018, 2019, 2020, 2…\n$ items          <int> 2, 8, 10, 1, 6, 1, 4, 5, 5, 10, 1, 3, 3, 9, 8\n$ price_per_item <dbl> 3.91, 4.72, 5.59, 3.91, 4.72, 5.59, 3.91, 4.72, 5.59, 3…\n$ totalprice     <dbl> 7.82, 37.76, 55.90, 3.91, 28.32, 5.59, 15.64, 23.60, 27…\n\n\n\nuntidy_data <- read_csv(\"data/untidy_data.csv\", \n                        show_col_types = FALSE)\n\nlonger_data <- pivot_longer(\n  data = untidy_data,\n  cols = itemsprice_2018:totalprice_2020,\n  names_to = c(\"category\", \"year\"),\n  names_sep = \"_\", \n  values_to = \"value\", \n  names_transform = list(year = as.integer),\n  values_transform = list(value = as.character) \n) \n\nwider_data <- pivot_wider(\n  data = longer_data,\n  id_cols = c(customer_id, year),\n  names_from = category,\n  values_from = value\n)\n\nsplit_data <- separate(\n  data = wider_data,\n  col = itemsprice,\n  into = c(\"items\", \"price_per_item\"),\n  sep = \" \", \n  remove = TRUE, \n  convert = TRUE\n) \n\nmutated_data <- mutate(\n  .data = split_data,\n  price_per_item = stringr::str_replace_all(\n    string = price_per_item, \n    pattern = \"[()]\", \n    replacement = \"\"\n  )\n) \n\ntidy_data <- type_convert(\n  df = mutated_data,\n  trim_ws = TRUE\n)\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  price_per_item = col_double(),\n  totalprice = col_double()\n)\n\n\n\ntidy_data <- read_csv(file = \"data/untidy_data.csv\",\n                      show_col_types = FALSE) %>%\n  pivot_longer(\n    cols = itemsprice_2018:totalprice_2020,\n    names_to = c(\"category\", \"year\"),\n    names_sep = \"_\", \n    values_to = \"value\", \n    names_transform = list(year = as.integer),\n    values_transform = list(value = as.character) \n  ) %>%\n  pivot_wider(\n    id_cols = c(customer_id, year),\n    names_from = category,\n    values_from = value\n  ) %>%\n  separate(\n    col = itemsprice,\n    into = c(\"items\", \"price_per_item\"),\n    sep = \" \", \n    remove = TRUE, \n    convert = TRUE\n  ) %>%\n  mutate(\n    price_per_item = stringr::str_replace_all(\n      string = price_per_item, \n      pattern = \"[()]\", \n      replacement = \"\"\n    )\n  ) %>%\n  type_convert(\n    trim_ws = TRUE\n  )\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  price_per_item = col_double(),\n  totalprice = col_double()\n)\n\ntidy_data #displays final tidy data\n\n# A tibble: 15 × 5\n   customer_id  year items price_per_item totalprice\n         <dbl> <int> <int>          <dbl>      <dbl>\n 1           1  2018     2           3.91       7.82\n 2           1  2019     8           4.72      37.8 \n 3           1  2020    10           5.59      55.9 \n 4           2  2018     1           3.91       3.91\n 5           2  2019     6           4.72      28.3 \n 6           2  2020     1           5.59       5.59\n 7           3  2018     4           3.91      15.6 \n 8           3  2019     5           4.72      23.6 \n 9           3  2020     5           5.59      28.0 \n10           4  2018    10           3.91      39.1 \n11           4  2019     1           4.72       4.72\n12           4  2020     3           5.59      16.8 \n13           5  2018     3           3.91      11.7 \n14           5  2019     9           4.72      42.5 \n15           5  2020     8           5.59      44.7"
  },
  {
    "objectID": "posts/week-11/index.html",
    "href": "posts/week-11/index.html",
    "title": "Week 11: Data Wrangling",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2\n──\n\n\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ stringr 1.5.0\n✔ tidyr   1.3.0     ✔ forcats 1.0.0\n✔ readr   2.1.3     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\nbudget <- read_csv(\"data/budget.csv\", show_col_types = FALSE)\n\nview(budget)\n\n\n# select single column by name, uses pipe operator\nproduct_dat <- budget %>% select(product)\n\n# select single column by number\nproduct_dat <- budget %>% select(2) \n\nproduct_dat <- budget %>% select(2,3)\n\n\n# to print column 2 n 3 - not assigned so prints by default\nbudget %>% select(2,3)\n\n# A tibble: 8 × 2\n  product sales_2019\n  <chr>        <dbl>\n1 widgets       2129\n2 gadgets        723\n3 widgets       1123\n4 gadgets       2022\n5 widgets       -728\n6 gadgets       -423\n7 widgets        633\n8 gadgets       1204\n\n#can also type name of variable to print\nproduct_dat\n\n# A tibble: 8 × 2\n  product sales_2019\n  <chr>        <dbl>\n1 widgets       2129\n2 gadgets        723\n3 widgets       1123\n4 gadgets       2022\n5 widgets       -728\n6 gadgets       -423\n7 widgets        633\n8 gadgets       1204\n\n#will look better rendered w html\nknitr::kable(product_dat)\n\n\n\n\nproduct\nsales_2019\n\n\n\n\nwidgets\n2129\n\n\ngadgets\n723\n\n\nwidgets\n1123\n\n\ngadgets\n2022\n\n\nwidgets\n-728\n\n\ngadgets\n-423\n\n\nwidgets\n633\n\n\ngadgets\n1204\n\n\n\n\n\n\n\ncolon notation\n\n# select columns individually\nsales2019 <- budget %>% select(region, product, sales_2019)\n\n# select columns with colon\nsales2019 <- budget %>% select(region:sales_2019)\n\n#select columns w colon\nyears <- budget %>% select(3:7)\nyears <- budget %>% select(sales_2019:satisfaction_2020)\nyears\n\n# A tibble: 8 × 6\n  sales_2019 sales_2020 expenses_2019 expenses_2020 satisfaction_2019 satisfac…¹\n       <dbl>      <dbl>         <dbl>         <dbl> <chr>             <chr>     \n1       2129       -517           822          -897 high              very high \n2        723         77          1037          1115 very high         very high \n3       1123      -1450          1004           672 high              neutral   \n4       2022       -945          -610           200 low               low       \n5       -728        -51          -801          -342 very low          very low  \n6       -423       -354            94          2036 neutral           high      \n7        633        790           783          -315 neutral           neutral   \n8       1204        426           433          -136 low               low       \n# … with abbreviated variable name ¹​satisfaction_2020\n\n# excluding colums using minus\n\n# de-select individual columns\nsales <- budget %>% select(-expenses_2019, -expenses_2020)\n\n# de-select a range of columns\nsales <- budget %>% select(-(expenses_2019:expenses_2020))\nsales\n\n# A tibble: 8 × 6\n  region product sales_2019 sales_2020 satisfaction_2019 satisfaction_2020\n  <chr>  <chr>        <dbl>      <dbl> <chr>             <chr>            \n1 North  widgets       2129       -517 high              very high        \n2 North  gadgets        723         77 very high         very high        \n3 South  widgets       1123      -1450 high              neutral          \n4 South  gadgets       2022       -945 low               low              \n5 East   widgets       -728        -51 very low          very low         \n6 East   gadgets       -423       -354 neutral           high             \n7 West   widgets        633        790 neutral           neutral          \n8 West   gadgets       1204        426 low               low              \n\n\n\n# select all rows where region equals North\nbudget %>% filter(region == \"North\")\n\n# A tibble: 2 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 North  widgets       2129       -517           822        -897 high    very h…\n2 North  gadgets        723         77          1037        1115 very h… very h…\n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n# select all rows where expenses_2020 were exactly equal to 200\nbudget %>% filter(expenses_2020 == 200)\n\n# A tibble: 1 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 South  gadgets       2022       -945          -610         200 low     low    \n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n# select all rows where sales_2019 was more than 100\nbudget %>% filter(sales_2019 > 100)\n\n# A tibble: 6 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 North  widgets       2129       -517           822        -897 high    very h…\n2 North  gadgets        723         77          1037        1115 very h… very h…\n3 South  widgets       1123      -1450          1004         672 high    neutral\n4 South  gadgets       2022       -945          -610         200 low     low    \n5 West   widgets        633        790           783        -315 neutral neutral\n6 West   gadgets       1204        426           433        -136 low     low    \n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n# everything but the North\nbudget %>% filter(region != \"North\")\n\n# A tibble: 6 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 South  widgets       1123      -1450          1004         672 high    neutral\n2 South  gadgets       2022       -945          -610         200 low     low    \n3 East   widgets       -728        -51          -801        -342 very l… very l…\n4 East   gadgets       -423       -354            94        2036 neutral high   \n5 West   widgets        633        790           783        -315 neutral neutral\n6 West   gadgets       1204        426           433        -136 low     low    \n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n\n\n# regions and products with profit in both 2019 and 2020\nprofit_both <- budget %>% \n  filter(\n    sales_2019 > expenses_2019,\n    sales_2020 > expenses_2020\n  )\n\n# the same as above, using & instead of a comma\nprofit_both <- budget %>% \n  filter(\n    sales_2019 > expenses_2019 &\n    sales_2020 > expenses_2020\n  )\n\n# regions and products with profit in 2019 or 2020\nprofit_either <- budget %>% \n  filter(\n    sales_2019 > expenses_2019 |\n    sales_2020 > expenses_2020\n  )\n\n# 2020 profit greater than 1000\nprofit_1000 <- budget %>%\n  filter(sales_2020 - expenses_2020 > 1000)\n\n\n\nin\n\n# retain any rows where region is north or south, and where product equals widget\nbudget %>%\n  filter(region %in% c(\"North\", \"South\"),\n         product == \"widgets\")\n\n# A tibble: 2 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 North  widgets       2129       -517           822        -897 high    very h…\n2 South  widgets       1123      -1450          1004         672 high    neutral\n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n# retain any rows where the region is not east or west, and where the product does not equal gadgets\nbudget %>%\n  filter(!region %in% c(\"East\", \"West\"),\n         product != \"gadgets\")\n\n# A tibble: 2 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 North  widgets       2129       -517           822        -897 high    very h…\n2 South  widgets       1123      -1450          1004         672 high    neutral\n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n\n\n#more in examples\na <- c(1:5)\n\n#looks through and outcomes true or false\n6 %in% a\n\n[1] FALSE\n\n1 %in% a\n\n[1] TRUE\n\n#to check if not in\nif(1 %in% a == TRUE){\n  \"yes\"\n}\n\n[1] \"yes\"\n\nif(6 %in% a == FALSE){\n  \"yes\"\n}\n\n[1] \"yes\"\n\n#default variable 'letters' prints out a-z\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nLETTERS\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\nwhich(letters %in% \"g\", arr.ind = TRUE) #where is index of letter\n\n[1] 7\n\n\n\n\narrange\n\n# arranging the table \n# first by product in alphabetical order\n# then by \"region\" in reverse alphabetical order\nbudget %>%\n  arrange(product, desc(region))\n\n# A tibble: 8 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 West   gadgets       1204        426           433        -136 low     low    \n2 South  gadgets       2022       -945          -610         200 low     low    \n3 North  gadgets        723         77          1037        1115 very h… very h…\n4 East   gadgets       -423       -354            94        2036 neutral high   \n5 West   widgets        633        790           783        -315 neutral neutral\n6 South  widgets       1123      -1450          1004         672 high    neutral\n7 North  widgets       2129       -517           822        -897 high    very h…\n8 East   widgets       -728        -51          -801        -342 very l… very l…\n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\nbudget %>%\n  mutate(region = factor(region, levels = c(\"North\", \"South\", \"East\", \"West\"))) %>%\n  filter(product == \"gadgets\") %>%\n  arrange(region)\n\n# A tibble: 4 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <fct>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 North  gadgets        723         77          1037        1115 very h… very h…\n2 South  gadgets       2022       -945          -610         200 low     low    \n3 East   gadgets       -423       -354            94        2036 neutral high   \n4 West   gadgets       1204        426           433        -136 low     low    \n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n\n\n\nMutate\n\nbudget2 <- budget %>%\n  mutate(\n    sales = sales_2019 + sales_2020,\n    expenses = expenses_2019 + expenses_2020,\n    profit = sales - expenses,\n    region = paste(region, \"Office\")\n  )\n\n\n\nMutate with Logic Operators\n\nbudget2 <- budget2 %>%\n  mutate(profit_category = profit > 0,\n         product = as.factor(product))\n\n\n\nUsing case_when\n\nbudget3 <- budget2 %>%\n  mutate(profit_category = case_when(profit > 0 ~ \"PROFIT\",\n                                     profit < 0 ~ \"NO PROFIT\"))\n\n\n# create a column where people get a bonus if customer satisfaction was overall high or very high\n\nbonus <- budget3 %>%\n  mutate(bonus_2019 = case_when(satisfaction_2019 %in% c(\"very low\", \"low\", \"neutral\") ~ \"no bonus\",\n                                satisfaction_2019 %in% c(\"high\", \"very high\") ~ \"bonus\"))\n\n\n# new management takes over - people only get a bonus if customer satisfaction was overall high or very high AND if a profit was returned\n\nbonus2 <- budget3 %>%\n  mutate(bonus_2020 = case_when(satisfaction_2020 == \"high\" & \n                                  profit_category == \"PROFIT\" ~ \"bonus\",\n                                satisfaction_2020 == \"very high\" & \n                                  profit_category == \"PROFIT\" ~ \"bonus\",\n                                TRUE ~ \"No bonus\")) # set all other values to \"no bonus\"\n\n\n\nSummarise\n\nbudget4 <- budget %>%\n  select(-satisfaction_2019, -satisfaction_2020) %>%\n  pivot_longer(cols = sales_2019:expenses_2020,\n               names_to = c(\"type\", \"year\"),\n               names_sep = \"_\",\n               values_to = \"value\") %>%\n  pivot_wider(names_from = type,\n              values_from = value)\n\nhead(budget4) # check the format\n\n# A tibble: 6 × 5\n  region product year  sales expenses\n  <chr>  <chr>   <chr> <dbl>    <dbl>\n1 North  widgets 2019   2129      822\n2 North  widgets 2020   -517     -897\n3 North  gadgets 2019    723     1037\n4 North  gadgets 2020     77     1115\n5 South  widgets 2019   1123     1004\n6 South  widgets 2020  -1450      672\n\n\n\nbudget4 %>%\n  summarise(\n    mean_sales = mean(sales),\n    mean_expenses = mean(expenses),\n    min_profit = min(expenses - sales),\n    max_profit = max(expenses - sales)\n  )\n\n# A tibble: 1 × 4\n  mean_sales mean_expenses min_profit max_profit\n       <dbl>         <dbl>      <dbl>      <dbl>\n1       291.          318.      -2632       2390\n\n\n\n\nGroup By\n\nyear_prod <- budget4 %>%\n  group_by(year, product) %>%\n  summarise(\n    mean_sales = mean(sales),\n    mean_expenses = mean(expenses),\n    min_profit = min(expenses - sales),\n    max_profit = max(expenses - sales)\n  ) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\nyear_prod\n\n# A tibble: 4 × 6\n  year  product mean_sales mean_expenses min_profit max_profit\n  <chr> <chr>        <dbl>         <dbl>      <dbl>      <dbl>\n1 2019  gadgets       882.          238.      -2632        517\n2 2019  widgets       789.          452       -1307        150\n3 2020  gadgets      -199           804.       -562       2390\n4 2020  widgets      -307          -220.      -1105       2122\n\n\n\n# arrange by maximum profit\nyear_prod %>%\n  arrange(desc(max_profit))\n\n# A tibble: 4 × 6\n  year  product mean_sales mean_expenses min_profit max_profit\n  <chr> <chr>        <dbl>         <dbl>      <dbl>      <dbl>\n1 2020  gadgets      -199           804.       -562       2390\n2 2020  widgets      -307          -220.      -1105       2122\n3 2019  gadgets       882.          238.      -2632        517\n4 2019  widgets       789.          452       -1307        150\n\n# filter out gadgets\nyear_prod %>%\n  filter(product != \"gadgets\")\n\n# A tibble: 2 × 6\n  year  product mean_sales mean_expenses min_profit max_profit\n  <chr> <chr>        <dbl>         <dbl>      <dbl>      <dbl>\n1 2019  widgets       789.          452       -1307        150\n2 2020  widgets      -307          -220.      -1105       2122\n\n\n\n# return top 3 sales\nbudget4 %>%\n  slice_max(n = 3, order_by = sales)\n\n# A tibble: 3 × 5\n  region product year  sales expenses\n  <chr>  <chr>   <chr> <dbl>    <dbl>\n1 North  widgets 2019   2129      822\n2 South  gadgets 2019   2022     -610\n3 West   gadgets 2019   1204      433\n\n\n\n# return top sale for each region\nbudget4 %>%\n  group_by(region) %>%\n  slice_max(n = 1, order_by = sales)\n\n# A tibble: 4 × 5\n# Groups:   region [4]\n  region product year  sales expenses\n  <chr>  <chr>   <chr> <dbl>    <dbl>\n1 East   widgets 2020    -51     -342\n2 North  widgets 2019   2129      822\n3 South  gadgets 2019   2022     -610\n4 West   gadgets 2019   1204      433\n\n\n\n\nRounding\n\nyear_prod %>%\n  mutate(across(.cols = mean_sales:max_profit, \n                .fns = round))\n\n# A tibble: 4 × 6\n  year  product mean_sales mean_expenses min_profit max_profit\n  <chr> <chr>        <dbl>         <dbl>      <dbl>      <dbl>\n1 2019  gadgets        882           238      -2632        517\n2 2019  widgets        789           452      -1307        150\n3 2020  gadgets       -199           804       -562       2390\n4 2020  widgets       -307          -220      -1105       2122\n\nround(0.5)\n\n[1] 0\n\nround(1.5)\n\n[1] 2\n\n#!!!!!! redefining round so 5s round up !!!!!! \nround <- function(x, digits = 0) {\n  posneg = sign(x)\n  z = abs(x)*10^digits\n  z = z + 0.5 + sqrt(.Machine$double.eps)\n  z = trunc(z)\n  z = z/10^digits\n  z*posneg\n}\n\nround(0.5)\n\n[1] 1\n\nround(1.5)\n\n[1] 2\n\n# remove new round() method\nrm(round)\n\n\n\nMissing Values\n\nmissing_bad <- budget4 %>%\n  mutate(expenses = ifelse(\n    test = year == 2020 & region == \"South\", \n    yes = 0, # value if above conditions are met\n    no = expenses # value if above conditions are not met\n  ))\n\n\nmissing_bad <- budget4 %>%\n  mutate(expenses = case_when(\n    # set to 0 when year is 2020 and region is North\n    year == 2020 & region == \"South\" ~ 0, \n    # otherwise, set to the value in the expenses column\n    TRUE ~ expenses   \n  ))\n\n# set sales values to \"missing\" for North 2020 rows\nmissing_bad <- missing_bad %>%\n  mutate(sales = ifelse(year == 2020 & region == \"North\", \n                        \"missing\", \n                        sales))\n\n# check structure of data, sales now character\nstr(missing_bad)\n\ntibble [16 × 5] (S3: tbl_df/tbl/data.frame)\n $ region  : chr [1:16] \"North\" \"North\" \"North\" \"North\" ...\n $ product : chr [1:16] \"widgets\" \"widgets\" \"gadgets\" \"gadgets\" ...\n $ year    : chr [1:16] \"2019\" \"2020\" \"2019\" \"2020\" ...\n $ sales   : chr [1:16] \"2129\" \"missing\" \"723\" \"missing\" ...\n $ expenses: num [1:16] 822 -897 1037 1115 1004 ...\n\n# set sales values to \"missing\" for North 2020 rows\nmissing_bad <- missing_bad %>%\n  mutate(sales = as.character(sales),\n         sales = case_when(year == 2020 & region == \"North\" ~ \"missing\", \n                           TRUE ~ sales))\n\n\n# try to compute mean sales\nmissing_bad %>%\n  summarise(mean_sales = mean(sales))\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `mean_sales = mean(sales)`.\nCaused by warning in `mean.default()`:\n! argument is not numeric or logical: returning NA\n\n\n# A tibble: 1 × 1\n  mean_sales\n       <dbl>\n1         NA\n\n\n\n\nConvert missing to NA\n\nmissing_data <- missing_bad %>%\n  mutate(\n    # set \"0\" values to NA using ifelse\n    expenses = ifelse(expenses == 0, NA, expenses),\n    # set \"missing\" values to NA using case_when\n    sales = case_when(sales == \"missing\" ~ NA_character_,\n                      TRUE ~ sales),\n    # convert to numeric\n    sales = as.numeric(sales)\n  )\n\nmissing_data %>%\n  group_by(region) %>%\n  summarise(\n    mean_sales = mean(sales),\n    mean_expenses = mean(expenses),\n    min_profit = min(expenses - sales),\n    max_profit = max(expenses - sales),\n    .groups = \"drop\")\n\n# A tibble: 4 × 5\n  region mean_sales mean_expenses min_profit max_profit\n  <chr>       <dbl>         <dbl>      <dbl>      <dbl>\n1 East        -389           247.       -291       2390\n2 North         NA           519.         NA         NA\n3 South        188.           NA          NA         NA\n4 West         763.          191.      -1105        150\n\nmissing_data %>%\n  group_by(region) %>%\n  summarise(\n    mean_sales = mean(sales, na.rm = TRUE),\n    mean_expenses = mean(expenses, na.rm = TRUE),\n    min_profit = min(expenses - sales, na.rm = TRUE),\n    max_profit = max(expenses - sales, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# A tibble: 4 × 5\n  region mean_sales mean_expenses min_profit max_profit\n  <chr>       <dbl>         <dbl>      <dbl>      <dbl>\n1 East        -389           247.       -291       2390\n2 North       1426           519.      -1307        314\n3 South        188.          197       -2632       -119\n4 West         763.          191.      -1105        150\n\nmissing_data %>%\n  group_by(year, product) %>%\n  summarise(\n    n_valid = sum(!is.na(sales)),\n    n_missing = sum(is.na(sales)),\n    prop_missing = mean(is.na(sales)),\n    .groups = \"drop\"\n  )\n\n# A tibble: 4 × 5\n  year  product n_valid n_missing prop_missing\n  <chr> <chr>     <int>     <int>        <dbl>\n1 2019  gadgets       4         0         0   \n2 2019  widgets       4         0         0   \n3 2020  gadgets       3         1         0.25\n4 2020  widgets       3         1         0.25\n\n# remove any rows with any missing values\ncomplete_data <- missing_data %>%\n  drop_na()\n\n# remove any rows that are missing a value for sales\ncomplete_sales <- missing_data %>%\n  drop_na(sales)\n\n\ncomplete_data\n\n# A tibble: 12 × 5\n   region product year  sales expenses\n   <chr>  <chr>   <chr> <dbl>    <dbl>\n 1 North  widgets 2019   2129      822\n 2 North  gadgets 2019    723     1037\n 3 South  widgets 2019   1123     1004\n 4 South  gadgets 2019   2022     -610\n 5 East   widgets 2019   -728     -801\n 6 East   widgets 2020    -51     -342\n 7 East   gadgets 2019   -423       94\n 8 East   gadgets 2020   -354     2036\n 9 West   widgets 2019    633      783\n10 West   widgets 2020    790     -315\n11 West   gadgets 2019   1204      433\n12 West   gadgets 2020    426     -136\n\ncomplete_sales\n\n# A tibble: 14 × 5\n   region product year  sales expenses\n   <chr>  <chr>   <chr> <dbl>    <dbl>\n 1 North  widgets 2019   2129      822\n 2 North  gadgets 2019    723     1037\n 3 South  widgets 2019   1123     1004\n 4 South  widgets 2020  -1450       NA\n 5 South  gadgets 2019   2022     -610\n 6 South  gadgets 2020   -945       NA\n 7 East   widgets 2019   -728     -801\n 8 East   widgets 2020    -51     -342\n 9 East   gadgets 2019   -423       94\n10 East   gadgets 2020   -354     2036\n11 West   widgets 2019    633      783\n12 West   widgets 2020    790     -315\n13 West   gadgets 2019   1204      433\n14 West   gadgets 2020    426     -136"
  },
  {
    "objectID": "posts/week-12/index.html",
    "href": "posts/week-12/index.html",
    "title": "Week 12: Customizations",
    "section": "",
    "text": "library(tidyverse)   # data wrangling functions\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ggthemes)    # for themes\nlibrary(patchwork)   # for combining plots\nlibrary(plotly)      # for interactive plots\n\nWarning: package 'plotly' was built under R version 4.2.3\n\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n# devtools::install_github(\"hrbrmstr/waffle\")\nlibrary(waffle)      # for waffle plots\n\nWarning: package 'waffle' was built under R version 4.2.3\n\nlibrary(ggbump)      # for bump plots\n\nWarning: package 'ggbump' was built under R version 4.2.3\n\nlibrary(ggwordcloud) # for word clouds\n\nWarning: package 'ggwordcloud' was built under R version 4.2.3\n\nlibrary(tidytext)    # for manipulating text for word clouds\n\nWarning: package 'tidytext' was built under R version 4.2.3\n\nlibrary(sf)          # for mapping geoms\n\nWarning: package 'sf' was built under R version 4.2.3\n\n\nLinking to GEOS 3.9.3, GDAL 3.5.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(rnaturalearth) # for map data\n\nWarning: package 'rnaturalearth' was built under R version 4.2.3\n\nlibrary(rnaturalearthdata) # extra mapping data\n\nWarning: package 'rnaturalearthdata' was built under R version 4.2.3\n\n\n\nAttaching package: 'rnaturalearthdata'\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\nlibrary(gganimate)   # for animated plots\n\nWarning: package 'gganimate' was built under R version 4.2.3\n\ntheme_set(theme_light())\n\n\nDefaults\n\n# update column specification\nct <- cols(issue_category = col_factor(levels = c(\"tech\", \"returns\", \"sales\", \"other\")))\n\n# load data\nsurvey_data <- read_csv(file = \"data/survey_data.csv\",\n                        col_types = ct)\n\n\n# create bar plot\nbar <- ggplot(data = survey_data, \n              mapping = aes(x = issue_category,\n                            fill = issue_category)) +\n  geom_bar(show.legend = FALSE) +\n  labs(x = \"Issue Category\", \n       y = \"Count\",\n       title = \"Calls by Issue Category\")\n\n\n#create scatterplot\npoint <- ggplot(data = survey_data, \n                mapping = aes(x = wait_time, \n                              y = call_time,\n                              color = issue_category)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = lm, formula = y~x) +\n  labs(x = \"Wait Time\",\n       y = \"Call Time\",\n       color = \"Issue Category\",\n       title = \"Wait Time by Call Time\")\n\n\nbar + point\n\n\n\n\n\n\nAnnotations\n\nbar +\n  # add left-justified text to the second bar\n  annotate(geom = \"text\",\n           label = \"Our goal is to\\nreduce this\\ncategory\",\n           x = 1.65, y = 150,\n           hjust = 0, vjust = 1, \n           color = \"white\", fontface = \"bold\",\n           angle = 45) +\n  # add a centred label to the third bar\n  annotate(geom = \"label\",\n           label = \"Our goal is\\nto increase this\\ncategory\",\n           x = 3, y = 75,\n           hjust = 0.5, vjust = 1, \n           color = \" darkturquoise\", fontface = \"bold\")\n\n\n\n\n\npoint +\n  # add a rectangle surrounding long call times\n  annotate(geom = \"rect\",\n           xmin = 100, xmax = 275,\n           ymin = 140, ymax = 180,\n           fill = \"transparent\", color = \"red\") +\n  # add a text label\n  annotate(\"text\",\n           x = 260, y = 120,\n           label = \"outliers\") +\n  # add an line with an arrow from the text to the box\n  annotate(geom = \"segment\", \n           x = 240, y = 120, \n           xend = 200, yend = 135,\n           arrow = arrow(length = unit(0.5, \"lines\"))) +\n  # add a curved line with an arrow \n  # from the text to a wait time outlier\n  annotate(geom = \"curve\", \n          x = 280, y = 120, \n          xend = 320, yend = 45,\n          curvature = -0.5,\n          arrow = arrow(length = unit(0.5, \"lines\")))\n\n\n\n\n\nsurvey_data <- read_csv(file = \"data/survey_data.csv\",\n                        show_col_types = FALSE)\n\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nggplot(survey_data, aes(x = wait_time)) +\n  scale_x_continuous(name = \"Wait time (seconds)\",\n                     breaks = seq(0, 600, 60)) +\n  geom_freqpoly(boundary = 0, binwidth = 15, \n                color = \"black\")"
  },
  {
    "objectID": "posts/week-13-slides/index.html#week-13-slides-with-revealjs",
    "href": "posts/week-13-slides/index.html#week-13-slides-with-revealjs",
    "title": "Week 13: Slide Decks",
    "section": "Week 13: Slides with Revealjs",
    "text": "Week 13: Slides with Revealjs\nhttps://quarto.org/docs/presentations/revealjs/"
  },
  {
    "objectID": "posts/week-13-slides/index.html#second-slide",
    "href": "posts/week-13-slides/index.html#second-slide",
    "title": "Week 13: Slide Decks",
    "section": "Second slide",
    "text": "Second slide\n\ntest text of second slide\ntext of second slide\neven more text of second slide"
  },
  {
    "objectID": "posts/week-13-slides/index.html#third-slide",
    "href": "posts/week-13-slides/index.html#third-slide",
    "title": "Week 13: Slide Decks",
    "section": "Third slide",
    "text": "Third slide\n:::\n\nadding increment colons thing\nnot sure if it’s gonna work\nhm\nadded a space\n\n:::"
  },
  {
    "objectID": "posts/week-13-slides/index.html#multi-column",
    "href": "posts/week-13-slides/index.html#multi-column",
    "title": "Week 13: Slide Decks",
    "section": "Multi-column",
    "text": "Multi-column\n:::: {.columns}\n\nTest text for the column\n\n::: {.column width=“30%”}\nWill this be a bigger column? Test text."
  },
  {
    "objectID": "posts/week-3/index.html",
    "href": "posts/week-3/index.html",
    "title": "Week 3: Qmd Skills",
    "section": "",
    "text": "1\n\nBe able to make a new .qmd document\n\nyes. - green plus icons or from file menu.\n\n\n2\n\nBe able to render a .qmd document\n\nyes. - through render button.\n\n\n3\n\nExplain the difference between the source editor view and visual editor view in Rstudio.\n\nsource view is plain text characters, visual view is rendered form of plain text that’s interpreted to a formatted markdown.\n\n\n4\n\nBe able to insert simple markdown plain text (headers, lists, paragraphs), and render the document.\n\n\nThis is a header\n\ntest text incoming:\n\nregular test of a text , regular test of a fancy test\nquick maths: 450 6538 12500000\n\nhaha jk why is this purple\n\n\n\n\n\n\n5\n\nBe aware of resources to help you learn more about markdown options.\n\n![Caption](image.png)\n\\(insert math equation here\\) \\(x=1\\)\ngrey square maker\nhttps://www.google.com\n\n\n6\n\nBe able to insert an R code chunk, and show the output in the rendered document.\n\n-macro for quick insert Running R code chunks in a qmd pressing play copy/paste into console highlight then command-enter (mac) precedence issues (first to last)\nalt + ctrl + i , shortcut to make R space block thingy\n\ncat(\"hello \")\n\nhello \n\ncat(\"pressing play runs the chunk into the console\")\n\npressing play runs the chunk into the console\n\n2+2\n\n[1] 4\n\n\n\n1:10\n1:5\n1:20\n\ncan highlight portion of code in R chunk, type ctrl + enter to run selected part(s)\nsyntax for R chunk #| and press tab to see options for parameters\n\n\n7\n\nBe aware of R code chunk options, and how to use eval, messages, error, warning, and echo.\n\n\nhist(mtcars$mpg)\n\n\n\n\"b\" + 5\n\nError in \"b\" + 5: non-numeric argument to binary operator\n\n\n\nlibrary(dplyr)\n\n\n\n8\n\nBe able to set code chunk options per chunk, and/or for the whole document. Understand rules for precedence (which options will apply if both are set.)\nyes, using execute in top-level yml - chunk options > global options\n\n\n\n9\n\nWrite inline r code.\n8\nMy weekly MTA fare is 11 dollars.\n\n\n\n10\n\nExplain how the rendering environment is different from the Rstudio environment.\n\n\na <- 50\nb <- 100\n\nc <- a+b\n\nrestarting R restarts the Rstudio environment as new, the rendering environment is its own separate R\n\n\n11\n\nBe aware of more advanced quarto options for html documents, and try some of the options. :("
  },
  {
    "objectID": "posts/week-4/index.html",
    "href": "posts/week-4/index.html",
    "title": "Week 4: Data Visualization",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(patchwork)\nlibrary(ggthemes)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union"
  },
  {
    "objectID": "posts/week-4/index.html#data-types",
    "href": "posts/week-4/index.html#data-types",
    "title": "Week 4: Data Visualization",
    "section": "Data Types",
    "text": "Data Types\n\na <- 2.5 # assigning character/variable\n\nclass(a) # find out it's numeric\n\n[1] \"numeric\"\n\ntypeof(a) # find out it's a double\n\n[1] \"double\"\n\nis.integer(a) # find out it's not an integer (integers don't have decimals)\n\n[1] FALSE\n\nas.integer(a) # rounds (2.5) down to an integer (2)\n\n[1] 2\n\nis.character(a) # find out if it's character or not\n\n[1] FALSE\n\n\n\ninteger(length = 5)\n\n[1] 0 0 0 0 0\n\nnumeric(length = 5)\n\n[1] 0 0 0 0 0\n\n\n\n# logical/boolean\ntypeof(TRUE) # uppercase true makes logical variables\n\n[1] \"logical\"\n\nclass(TRUE) \n\n[1] \"logical\"\n\nis.logical(FALSE) # same with uppercase false\n\n[1] TRUE\n\nas.logical(1) # one will be seen as true\n\n[1] TRUE\n\nas.logical(0) # zero will be seen as false\n\n[1] FALSE\n\nlogical(length = 3) # initializes logical vector three times\n\n[1] FALSE FALSE FALSE"
  },
  {
    "objectID": "posts/week-4/index.html#tidy-data",
    "href": "posts/week-4/index.html#tidy-data",
    "title": "Week 4: Data Visualization",
    "section": "Tidy Data",
    "text": "Tidy Data\n\n# tidy data must have every column a variable, every row an observation, and every cell a single value\nlibrary(tidyr)\n\natla <- tibble(\n  name = c(\"Katara\", \"Toph\", \"Sokka\", \"Zuko\", \"Azula\", \"Suki\", \"Princess Yue\"),\n  bends = c(\"water\", \"earth\", NA, \"fire\", \"fire\", NA, \"water\"),\n  friendly = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE),\n  nation = c(\"water tribe\",\"earth kingdom\",\"water tribe\",\"fire nation\",\"fire nation\",\"earth kingdom\",\"water tribe\"),\n  personal_rating = c(7,10,5,8,2,10,6) # out of ten\n)\natla # tibble name prints table\n\n# A tibble: 7 × 5\n  name         bends friendly nation        personal_rating\n  <chr>        <chr> <lgl>    <chr>                   <dbl>\n1 Katara       water TRUE     water tribe                 7\n2 Toph         earth TRUE     earth kingdom              10\n3 Sokka        <NA>  TRUE     water tribe                 5\n4 Zuko         fire  TRUE     fire nation                 8\n5 Azula        fire  FALSE    fire nation                 2\n6 Suki         <NA>  TRUE     earth kingdom              10\n7 Princess Yue water TRUE     water tribe                 6\n\ntidyr::as_tibble(atla)\n\n# A tibble: 7 × 5\n  name         bends friendly nation        personal_rating\n  <chr>        <chr> <lgl>    <chr>                   <dbl>\n1 Katara       water TRUE     water tribe                 7\n2 Toph         earth TRUE     earth kingdom              10\n3 Sokka        <NA>  TRUE     water tribe                 5\n4 Zuko         fire  TRUE     fire nation                 8\n5 Azula        fire  FALSE    fire nation                 2\n6 Suki         <NA>  TRUE     earth kingdom              10\n7 Princess Yue water TRUE     water tribe                 6"
  },
  {
    "objectID": "posts/week-4/index.html#ggplot2",
    "href": "posts/week-4/index.html#ggplot2",
    "title": "Week 4: Data Visualization",
    "section": "ggplot2",
    "text": "ggplot2\n\nsurvey_data <- read_csv(\"https://psyteachr.github.io/ads-v2/data/survey_data.csv\", show_col_types = FALSE)\n\n\nggplot()\n\n\n\nggplot(data = survey_data, mapping = aes(x = wait_time, y = satisfaction))\n\n\n\nggplot(survey_data, aes(x = wait_time, y = satisfaction)) + geom_point(color=\"red\", shape=18, size = 5) + geom_point(color=\"black\", shape=18, size = 3) + geom_smooth(method = \"lm\", color=\"green\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nggplot(survey_data, aes(x = wait_time, y = satisfaction, color = wait_time, size = satisfaction)) + geom_point()\n\n\n\nmin(survey_data$wait_time)\n\n[1] 23\n\nmax(survey_data$wait_time)\n\n[1] 314\n\nlength(survey_data$wait_time)\n\n[1] 707\n\n\n\nggplot(data=survey_data, mapping= aes(x=wait_time)) + geom_histogram(bins=50, color=\"orange\")"
  },
  {
    "objectID": "posts/week-5/index.html",
    "href": "posts/week-5/index.html",
    "title": "Week 5: Data Import",
    "section": "",
    "text": "library(tidyverse)     # includes readr & tibble\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(rio)           # for almost any data import/export\nlibrary(haven)         # for SPSS, Stata,and SAS files\nlibrary(readxl)        # for Excel files\nlibrary(googlesheets4) # for Google Sheets\n\n\n# list datasets built in to base R\ndata()\n\n# lists datasets in a specific package\ndata(package = \"tidyr\")\n\n\nglimpse(cars)\n\nRows: 50\nColumns: 2\n$ speed <dbl> 4, 4, 7, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 12, 12, 13, 13, 13…\n$ dist  <dbl> 2, 10, 4, 22, 16, 10, 18, 26, 34, 17, 28, 14, 20, 24, 28, 26, 34…\n\n# call print explicitly\nprint(table1)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  <chr>       <dbl>  <dbl>      <dbl>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n# more common method of just calling object name\ntable1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  <chr>       <dbl>  <dbl>      <dbl>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\ntibble::glimpse(table1)\n\nRows: 6\nColumns: 4\n$ country    <chr> \"Afghanistan\", \"Afghanistan\", \"Brazil\", \"Brazil\", \"China\", …\n$ year       <dbl> 1999, 2000, 1999, 2000, 1999, 2000\n$ cases      <dbl> 745, 2666, 37737, 80488, 212258, 213766\n$ population <dbl> 19987071, 20595360, 172006362, 174504898, 1272915272, 12804…\n\nsummary(table1)\n\n   country               year          cases          population       \n Length:6           Min.   :1999   Min.   :   745   Min.   :1.999e+07  \n Class :character   1st Qu.:1999   1st Qu.: 11434   1st Qu.:5.845e+07  \n Mode  :character   Median :2000   Median : 59113   Median :1.733e+08  \n                    Mean   :2000   Mean   : 91277   Mean   :4.901e+08  \n                    3rd Qu.:2000   3rd Qu.:179316   3rd Qu.:9.983e+08  \n                    Max.   :2000   Max.   :213766   Max.   :1.280e+09  \n\n\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\n\nlibrary(summarytools)\n\n\nAttaching package: 'summarytools'\n\n\nThe following object is masked from 'package:tibble':\n\n    view\n\n\n\nlibrary(rio)\n\ndemo_tsv <- import(file = \"data/demo.tsv\")\ndemo_csv  <- import(\"data/demo.csv\")  # comma-separated values\ndemo_xls  <- import(\"data/demo.xlsx\") # Excel format\ndemo_sav  <- import(\"data/demo.sav\")  # SPSS format\n\ndemo_tsv$factor <- as.factor(demo_tsv$factor)\n\nglimpse(demo_tsv)\n\nRows: 6\nColumns: 6\n$ character <chr> \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    <fct> high, low, med, high, low, med\n$ integer   <int> 1, 2, 3, 4, 5, 6\n$ double    <dbl> 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   <lgl> TRUE, TRUE, FALSE, FALSE, NA, TRUE\n$ date      <IDate> 2022-04-04, 2022-04-03, 2022-04-02, 2022-04-01, 2022-03-31, …\n\ndemo_tsv$character\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\ndemo_tsv$factor\n\n[1] high low  med  high low  med \nLevels: high low med\n\n\n\ngs4_deauth() # skip authorisation for public data\n\ndemo_gs4  <- googlesheets4::read_sheet(\n  ss = \"16dkq0YL0J7fyAwT1pdgj1bNNrheckAU_2-DKuuM6aGI\")\n\n✔ Reading from \"demo\".\n\n\n✔ Range 'Sheet1'.\n\n\n\navatar <- tibble(\n  name = c(\"Katara\", \"Toph\", \"Sokka\"),\n  bends = c(\"water\", \"earth\", NA),\n  friendly = TRUE,\n  numbers = c(1,2,3),\n  more_numbers = 1:3,\n)\n\n# print it\navatar\n\n# A tibble: 3 × 5\n  name   bends friendly numbers more_numbers\n  <chr>  <chr> <lgl>      <dbl>        <int>\n1 Katara water TRUE           1            1\n2 Toph   earth TRUE           2            2\n3 Sokka  <NA>  TRUE           3            3\n\n\n\navatar_by_row <- tribble(\n  ~name,    ~bends,  ~friendly, ~numbers,\n  \"Katara\", \"water\", TRUE, 1L,\n  \"Toph\",   \"earth\", TRUE, 2L,\n  \"Sokka\",  NA,      TRUE, 3L\n)\n\navatar_by_row\n\n# A tibble: 3 × 4\n  name   bends friendly numbers\n  <chr>  <chr> <lgl>      <int>\n1 Katara water TRUE           1\n2 Toph   earth TRUE           2\n3 Sokka  <NA>  TRUE           3\n\n\n\nrio::export(avatar, \"data/avatar.csv\")\n\n\ngs4_auth(email = \"leultimateruler@gmail.com\")\n\n# create a new sheet\nsheet_id <- gs4_create(name = \"demo-file\", \n                       sheets = \"letters\")\n\n✔ Creating new Sheet: \"demo-file\".\n\n\nAuto-refreshing stale OAuth token.\n\n# define the data table to save\nletter_data <- tibble(\n  character = LETTERS[1:5],\n  integer = 1:5,\n  double = c(1.1, 2.2, 3.3, 4.4, 5.5),\n  logical = c(T, F, T, F, T),\n  date = lubridate::today()\n)\n\nwrite_sheet(data = letter_data, \n            ss = sheet_id, \n            sheet = \"letters\")\n\n✔ Writing to \"demo-file\".\n\n\n✔ Writing to sheet 'letters'.\n\n## append some data\nnew_data <- tibble(\n  character = \"F\",\n  integer = 6L,\n  double = 6.6,\n  logical = FALSE,\n  date = lubridate::today()\n)\nsheet_append(data = new_data,\n             ss = sheet_id,\n             sheet = \"letters\")\n\n✔ Writing to \"demo-file\".\n\n\n✔ Appending 1 row to 'letters'.\n\n# read the data\ndemo <- read_sheet(ss = sheet_id, sheet = \"letters\")\n\n✔ Reading from \"demo-file\".\n\n\n✔ Range ''letters''."
  },
  {
    "objectID": "posts/week-5a/index.html",
    "href": "posts/week-5a/index.html",
    "title": "Week 5a: Loops & Logic",
    "section": "",
    "text": "loops & logic\n\n1 == 1\n\n[1] TRUE\n\n1 == 2\n\n[1] FALSE\n\nc(1, 2, 3) == c(2, 1, 3)\n\n[1] FALSE FALSE  TRUE\n\n1 == c(2, 1, 3)\n\n[1] FALSE  TRUE FALSE\n\n\n\n1 != 1\n\n[1] FALSE\n\n1 != 2\n\n[1] TRUE\n\n\n\n1 > 1\n\n[1] FALSE\n\n5 > 1\n\n[1] TRUE\n\n3 < 2\n\n[1] FALSE\n\n3 < 1\n\n[1] FALSE\n\nc(1, 2 ,3) > c(2, 1, 3)\n\n[1] FALSE  TRUE FALSE\n\n\n\n1 >= 1\n\n[1] TRUE\n\n5 >= 1\n\n[1] TRUE\n\n3 <= 2\n\n[1] FALSE\n\n\n\n# is 16 divisible by 4 AND 8\n16 %% 4 == 0 & 16 %% 8 == 0\n\n[1] TRUE\n\n16 %% 4 == 0 & 16 %% 3 == 0\n\n[1] FALSE\n\n16 %% 4 == 0 & 16 %% 8 == 0 & 16 %% 2 == 0\n\n[1] TRUE\n\n\n\n16 %% 4 == 0 | 16 %% 8 == 0\n\n[1] TRUE\n\n\n\n\nif else statements\n\na <- 1 # defines a to be a 1\n\nif (a == 1) {\n  print(a) # this happens if a == 1\n} else {\n  print(\"A is not 1\") # this happens if a is not 1\n}\n\n[1] 1\n\nif (a == 2) {\n    print(a)\n} else {\n  print(\"Hello world\")\n  }\n\n[1] \"Hello world\"\n\n\n\n# for loop\n\na <- c(1, 0, 1, 0, 0, 0, 1)\n\nfor (i in a) {\n  \n  if (i == 1) {\n    print(\"I'm a 1\")\n  } else {\n    print(\"I'm not a 1\")\n  }\n}\n\n[1] \"I'm a 1\"\n[1] \"I'm not a 1\"\n[1] \"I'm a 1\"\n[1] \"I'm not a 1\"\n[1] \"I'm not a 1\"\n[1] \"I'm not a 1\"\n[1] \"I'm a 1\"\n\n\nbasic syntax - for(){}, for(loop control){ loop steps: iterator <- vector1 break stops a loop\n\n\nwhile loops\n\ni <- 1\nwhile (i < 6) {\n  print(i)\n  i <- i + 1 # adds one each step of loop\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n\n\nrepeat loops\n\ni <- 0\nrepeat {\n  i <- i + 1\n  print(i)\n  if (i == 5) {\n    break\n  }\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nbraces not needed on one line"
  },
  {
    "objectID": "posts/week-6/index.html",
    "href": "posts/week-6/index.html",
    "title": "Week 6: Data Summaries",
    "section": "",
    "text": "library(tidyverse)   # data wrangling functions\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(kableExtra)  # for nice tables\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\ntweets <- readRDS(\"ncod_tweets.rds\")\n\nglimpse(tweets)\n\nRows: 28,626\nColumns: 90\n$ user_id                 <chr> \"1407407384146948116\", \"986008595622920193\", \"…\n$ status_id               <chr> \"1448018751828398082\", \"1448018601689194502\", …\n$ created_at              <dttm> 2021-10-12 20:12:27, 2021-10-12 20:11:52, 202…\n$ screen_name             <chr> \"Seanachaidh10\", \"_blayne__\", \"ShiguSquad\", \"M…\n$ text                    <chr> \"#LGBTQ #LGBT #Diversity #inclusion #NationalC…\n$ source                  <chr> \"Twitter for Android\", \"Twitter for iPhone\", \"…\n$ display_text_width      <dbl> 139, 52, 72, 179, 243, 196, 260, 233, 273, 75,…\n$ reply_to_status_id      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ reply_to_user_id        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ reply_to_screen_name    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ is_quote                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ is_retweet              <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ favorite_count          <int> 0, 0, 0, 0, 0, 2, 0, 1, 3, 0, 9, 5, 0, 0, 2, 1…\n$ retweet_count           <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n$ quote_count             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ reply_count             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ hashtags                <list> <\"LGBTQ\", \"LGBT\", \"Diversity\", \"inclusion\", \"…\n$ symbols                 <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ urls_url                <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ urls_t.co               <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ urls_expanded_url       <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ media_url               <list> \"http://pbs.twimg.com/media/FBhlYbGWUAA1Y6Y.j…\n$ media_t.co              <list> \"https://t.co/EnqHdxOVtX\", \"https://t.co/TVca…\n$ media_expanded_url      <list> \"https://twitter.com/Seanachaidh10/status/144…\n$ media_type              <list> \"photo\", \"photo\", NA, NA, \"photo\", NA, \"photo…\n$ ext_media_url           <list> \"http://pbs.twimg.com/media/FBhlYbGWUAA1Y6Y.j…\n$ ext_media_t.co          <list> \"https://t.co/EnqHdxOVtX\", <\"https://t.co/TVc…\n$ ext_media_expanded_url  <list> \"https://twitter.com/Seanachaidh10/status/144…\n$ ext_media_type          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ mentions_user_id        <list> NA, NA, NA, NA, NA, NA, <\"1425689378953654272…\n$ mentions_screen_name    <list> NA, NA, NA, NA, NA, NA, <\"NeerajDasi1\", \"Bein…\n$ lang                    <chr> \"und\", \"en\", \"en\", \"en\", \"und\", \"en\", \"en\", \"e…\n$ quoted_status_id        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_text             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_created_at       <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ quoted_source           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_favorite_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_retweet_count    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_user_id          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_screen_name      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_name             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_followers_count  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_friends_count    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_statuses_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_location         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_description      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ quoted_verified         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_status_id       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_text            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_created_at      <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ retweet_source          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_favorite_count  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_retweet_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_user_id         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_screen_name     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_name            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_followers_count <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_friends_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_statuses_count  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_location        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_description     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ retweet_verified        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ place_url               <chr> NA, NA, NA, NA, NA, NA, \"https://api.twitter.c…\n$ place_name              <chr> NA, NA, NA, NA, NA, NA, \"Itaunja\", NA, NA, NA,…\n$ place_full_name         <chr> NA, NA, NA, NA, NA, NA, \"Itaunja\", NA, NA, NA,…\n$ place_type              <chr> NA, NA, NA, NA, NA, NA, \"poi\", NA, NA, NA, NA,…\n$ country                 <chr> NA, NA, NA, NA, NA, NA, \"India\", NA, NA, NA, N…\n$ country_code            <chr> NA, NA, NA, NA, NA, NA, \"IN\", NA, NA, NA, NA, …\n$ geo_coords              <list> <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, …\n$ coords_coords           <list> <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, …\n$ bbox_coords             <list> <NA, NA, NA, NA, NA, NA, NA, NA>, <NA, NA, NA…\n$ status_url              <chr> \"https://twitter.com/Seanachaidh10/status/1448…\n$ name                    <chr> \"Sean Armstrong⚽✒🎧\", \"Blayne\", \"Karl aka Lin…\n$ location                <chr> \"Pittsburgh, PA\", \"\", \"London, Ontario\", \"Mass…\n$ description             <chr> \"⚽ #Author of Ace of Clubs (Expected publicat…\n$ url                     <chr> \"https://t.co/XBWuEUMTPP\", NA, NA, \"https://t.…\n$ protected               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ followers_count         <int> 301, 108, 806, 1315, 202, 92, 261, 79, 7520, 1…\n$ friends_count           <int> 152, 181, 2468, 362, 5003, 259, 515, 177, 416,…\n$ listed_count            <int> 0, 0, 6, 0, 0, 1, 0, 0, 11, 1, 7, 4, 7, 8, 8, …\n$ statuses_count          <int> 206, 254, 26983, 3166, 44820, 2858, 1012, 1049…\n$ favourites_count        <int> 325, 8537, 120476, 8668, 18220, 12039, 153, 45…\n$ account_created_at      <dttm> 2021-06-22 18:37:32, 2018-04-16 22:29:03, 201…\n$ verified                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ profile_url             <chr> \"https://t.co/XBWuEUMTPP\", NA, NA, \"https://t.…\n$ profile_expanded_url    <chr> \"https://www.seanachaidh.me/\", NA, NA, \"http:/…\n$ account_lang            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ profile_banner_url      <chr> \"https://pbs.twimg.com/profile_banners/1407407…\n$ profile_background_url  <chr> NA, NA, NA, \"http://abs.twimg.com/images/theme…\n$ profile_image_url       <chr> \"http://pbs.twimg.com/profile_images/140740748…\n\nhist(tweets$favorite_count) #fast way to get histogram\n\n\n\nggplot(tweets, aes(x=favorite_count))+geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlibrary(dplyr)\n\nfiltered_data <- tweets %>%\n  filter(favorite_count < 100) # thingy called pipe operator, sends data into next step aka filter\n\nggplot(tweets, aes(x=favorite_count))+geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nfavourite_summary <- summarise(tweets,\n                           mean_favs = mean(favorite_count),\n                           median_favs = median(favorite_count),\n                           min_favs = min(favorite_count),\n                           max_favs = max(favorite_count),\n                           sd_favs = sd(favorite_count),\n                           mean_RTs = mean(retweet_count),\n                           median_RTs = median(retweet_count),\n                           min_RTs = min(retweet_count),\n                           max_RTs = max(retweet_count),\n                           sd_RTs = sd(favorite_count))\n\nfavourite_summary\n\n# A tibble: 1 × 10\n  mean_…¹ media…² min_f…³ max_f…⁴ sd_favs mean_…⁵ media…⁶ min_RTs max_RTs sd_RTs\n    <dbl>   <dbl>   <int>   <int>   <dbl>   <dbl>   <dbl>   <int>   <int>  <dbl>\n1    29.7       3       0   22935    330.    3.17       0       0    2525   330.\n# … with abbreviated variable names ¹​mean_favs, ²​median_favs, ³​min_favs,\n#   ⁴​max_favs, ⁵​mean_RTs, ⁶​median_RTs\n\n\n\nggplot(tweets, aes(x = favorite_count)) +\n  geom_histogram(bins = 25) +\n  scale_x_continuous(trans = \"pseudo_log\", \n                     breaks = c(0, 1, 10, 100, 1000, 10000))\n\n\n\n\n\ntweet_summary <- tweets %>%\n  summarise(mean_favs = mean(favorite_count),\n            median_favs = quantile(favorite_count, .5),\n            n = n(),\n            min_date = min(created_at),\n            max_date = max(created_at))\n\nglimpse(tweet_summary)\n\nRows: 1\nColumns: 5\n$ mean_favs   <dbl> 29.71732\n$ median_favs <dbl> 3\n$ n           <int> 28626\n$ min_date    <dttm> 2021-10-10 00:10:02\n$ max_date    <dttm> 2021-10-12 20:12:27\n\n\n\ndate_from <- tweet_summary$min_date %>% # inline code\n  format(\"%d %B, %Y\")\ndate_to <- tweet_summary$max_date %>% \n  format(\"%d %B, %Y\")\n\n\ntweets_per_user <- tweets %>%\n  count(screen_name, sort = TRUE)\n\nhead(tweets_per_user)\n\n# A tibble: 6 × 2\n  screen_name         n\n  <chr>           <int>\n1 interest_outfit    35\n2 LeoShir2           33\n3 NRArchway          32\n4 dr_stack           32\n5 bhavna_95          25\n6 WipeHomophobia     23\n\n\n\nunique_users <- nrow(tweets_per_user)\nmost_prolific <- slice(tweets_per_user, 1) %>% \n  pull(screen_name)\nmost_prolific_n <- slice(tweets_per_user, 1) %>% \n  pull(n)\n\n\ntweets_grouped <- tweets %>%\n  group_by(verified)\n\nverified <- tweets_grouped %>%\n  summarise(count = n(),\n            mean_favs = mean(favorite_count),\n            mean_retweets = mean(retweet_count)) %>%\n  ungroup()\n\nverified\n\n# A tibble: 2 × 4\n  verified count mean_favs mean_retweets\n  <lgl>    <int>     <dbl>         <dbl>\n1 FALSE    26676      18.4          1.83\n2 TRUE      1950     184.          21.5"
  },
  {
    "objectID": "posts/week-6/index.html#extra-blogging-challenge",
    "href": "posts/week-6/index.html#extra-blogging-challenge",
    "title": "Week 6: Data Summaries",
    "section": "Extra blogging challenge",
    "text": "Extra blogging challenge\n\nlibrary(tidyverse)     # includes readr & tibble\nlibrary(rio)           # for almost any data import/export\nlibrary(haven)         # for SPSS, Stata,and SAS files\nlibrary(readxl)        # for Excel files\n\n\ndata(package = \"tidyr\")\n\n\ndata_census <- import(\"2018_Central_Park_Squirrel_Census_-_Squirrel_Data.csv\")\n\n\nglimpse(data_census)\n\nRows: 3,023\nColumns: 31\n$ X                                            <dbl> -73.95613, -73.96886, -73…\n$ Y                                            <dbl> 40.79408, 40.78378, 40.77…\n$ `Unique Squirrel ID`                         <chr> \"37F-PM-1014-03\", \"21B-AM…\n$ Hectare                                      <chr> \"37F\", \"21B\", \"11B\", \"32E…\n$ Shift                                        <chr> \"PM\", \"AM\", \"PM\", \"PM\", \"…\n$ Date                                         <int> 10142018, 10192018, 10142…\n$ `Hectare Squirrel Number`                    <int> 3, 4, 8, 14, 5, 3, 2, 2, …\n$ Age                                          <chr> \"\", \"\", \"\", \"Adult\", \"Adu…\n$ `Primary Fur Color`                          <chr> \"\", \"\", \"Gray\", \"Gray\", \"…\n$ `Highlight Fur Color`                        <chr> \"\", \"\", \"\", \"\", \"Cinnamon…\n$ `Combination of Primary and Highlight Color` <chr> \"+\", \"+\", \"Gray+\", \"Gray+…\n$ `Color notes`                                <chr> \"\", \"\", \"\", \"Nothing sele…\n$ Location                                     <chr> \"\", \"\", \"Above Ground\", \"…\n$ `Above Ground Sighter Measurement`           <chr> \"\", \"\", \"10\", \"\", \"\", \"\",…\n$ `Specific Location`                          <chr> \"\", \"\", \"\", \"\", \"on tree …\n$ Running                                      <lgl> FALSE, FALSE, FALSE, FALS…\n$ Chasing                                      <lgl> FALSE, FALSE, TRUE, FALSE…\n$ Climbing                                     <lgl> FALSE, FALSE, FALSE, FALS…\n$ Eating                                       <lgl> FALSE, FALSE, FALSE, TRUE…\n$ Foraging                                     <lgl> FALSE, FALSE, FALSE, TRUE…\n$ `Other Activities`                           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ Kuks                                         <lgl> FALSE, FALSE, FALSE, FALS…\n$ Quaas                                        <lgl> FALSE, FALSE, FALSE, FALS…\n$ Moans                                        <lgl> FALSE, FALSE, FALSE, FALS…\n$ `Tail flags`                                 <lgl> FALSE, FALSE, FALSE, FALS…\n$ `Tail twitches`                              <lgl> FALSE, FALSE, FALSE, FALS…\n$ Approaches                                   <lgl> FALSE, FALSE, FALSE, FALS…\n$ Indifferent                                  <lgl> FALSE, FALSE, FALSE, FALS…\n$ `Runs from`                                  <lgl> FALSE, FALSE, FALSE, TRUE…\n$ `Other Interactions`                         <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ `Lat/Long`                                   <chr> \"POINT (-73.9561344937861…\n\nsquirrel <- data_census$`Unique Squirrel ID`\ncolor <- data_census$`Primary Fur Color`\nfood <- data_census$Eating\n\n\nggplot(data_census, aes(x = squirrel, y = color)) + geom_point(color=\"black\", shape=18, size = 4) + geom_point(color=\"lightgreen\", shape=18, size = 2.5)\n\n\n\nggplot(data_census, aes(x = squirrel, y = food))+geom_col(linewidth = 3, fill = \"firebrick\")+scale_x_discrete(labels = abbreviate, limits = c(\"42C-AM-1007-02\",\"36E-AM-1013-02\",\"3F-PM-1013-03\", \"2F-PM-1014-03\", \"15G-PM-1019-01\",\"1I-PM-1012-04\",\"34A-PM-1013-04\"))+ggtitle(\"Was the squirrel eating?\")\n\nWarning: Removed 3016 rows containing missing values (`position_stack()`)."
  },
  {
    "objectID": "posts/week-7/index.html",
    "href": "posts/week-7/index.html",
    "title": "Week 7: More ggplot2",
    "section": "",
    "text": "library(ggplot2)\n\nX_axis<-c(1,10,25,38,49,54,63,69)\nY_axis<-c(8,15,24,32,40,58,61,69)\ndata_plot<-data.frame(X_axis,Y_axis)\n\nscatter<-ggplot(data_plot, aes(x=X_axis,y=Y_axis))+\n  geom_point(shape=18, size=4,color=\"blue\")+\n  geom_point(shape=18, size=2,color=\"yellow\")+\n  geom_smooth(method=\"lm\",se=FALSE, color=\"blue\", size=.5)+\n  xlab(\"This is the X axis plots\")+\n  ylab(\"This is the Y axis plots\")+\n  coord_cartesian(xlim=c(0,75), ylim=c(0,75))+\n  scale_x_continuous(breaks=seq(0,75,10), expand=c(0,0))+\n  scale_y_continuous(breaks=seq(0,75,10), expand=c(0,0))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nscatter\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\ndf <- data.frame(map=c(\"PL\", \"LS\", \"BE\", \"BD\", \"HN\", \"FE\", \"ST\", \"IX\", \"AT\", NA),\n                winrate=c(53.8, 45.5, 52.9, 48.3, 58.3, 16.7, 40.0, 40.0, 35.7, 0))\n\nlibrary(ggplot2)\n\nggplot(data=df, aes(x=map, y=winrate, group=1)) +\n  geom_line(linetype = \"dashed\",color=\"yellow\", linewidth=.75)+\n  geom_point(color = \"green\")+theme_dark(base_line_size = 1.75)+lims(y=c(0,100))\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n✔ purrr   1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\ngrades <- c(2.5, 8, 4)\nstudents <- c(\"A\", \"B\", \"C\")\n\n# same number of vectors, can list into tibble\n\nstudent_performance <- tibble(students, grades)\n\n# alternative syntax\n\nstudent_performance <- tibble(\n  grades = c(2.5,8,4),\n  students = c(\"A\",\"B\",\"C\")\n  )\n\n# ggplot bar graph\nggplot(student_performance, aes(x = students, y = grades))+geom_bar(stat = \"identity\", width = 0.25, fill = \"white\", colour = \"blue\", linewidth = 1)+lims(y=c(0,10))+scale_y_continuous(breaks = 0:10, limits = c(0,10))+theme_bw(base_size = 14)+geom_text(label = grades, position = position_dodge(width  = .9), vjust = -0.4)+xlab(\"Students\")+ylab(\"Grades\")+ggtitle(\"Student Performance\")\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\ntier <- c(12.5, 12.5, 10, 2, 9, 6, 3, 7)\nagents <- c(\"Sova\", \"Killjoy\", \"Cypher\", \"Omen\", \"Raze\", \"Neon\", \"Chamber\", \"Harbor\")\nlimit <- c(.5,.5,.5,.5,.5,.5,.5,.5)\n\nval <- tibble(\n  tier = c(12.5, 12.5, 10, 2, 9, 6, 3, 7),\n  agents = c(\"Sova\", \"Killjoy\", \"Cypher\", \"Omen\", \"Raze\", \"Neon\", \"Chamber\", \"Harbor\")\n  )\n\n# ggplot bar graph\nggplot(val, aes(x = agents, y = tier))+geom_bar(stat = \"identity\", width = 0.5, fill = \"firebrick\", colour = \"black\", linewidth = 1)+lims(y=c(0,15))+scale_y_continuous(breaks = 0:15, limits = c(0,15))+theme_dark(base_size = 14)+geom_text(label = tier, position = position_dodge(width  = .9), vjust = -1.5)+xlab(\"Agents\")+ylab(\"Tier\")+ggtitle(\"Valorant Agents Tier List\")+\n  geom_errorbar(aes(ymin = tier - limit,\n                    ymax = tier + limit),\n                width = .2, position = position_dodge(width = .5))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale."
  },
  {
    "objectID": "posts/week-8/index.html",
    "href": "posts/week-8/index.html",
    "title": "Week 8: Data Relations",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "posts/week-8/index.html#dplyr-mutate",
    "href": "posts/week-8/index.html#dplyr-mutate",
    "title": "Week 8: Data Relations",
    "section": "Dplyr Mutate",
    "text": "Dplyr Mutate\n\norders_B <- tibble(\n  id = c(2, 3, 4, 4, 5, 5, 6, 6, 7),\n  items = c(10, 18, 21, 23, 9, 11, 11, 12, 3)\n)\n\n# adds new column\norders_B %>%\n  mutate(satisfaction = NA)\n\n# A tibble: 9 × 3\n     id items satisfaction\n  <dbl> <dbl> <lgl>       \n1     2    10 NA          \n2     3    18 NA          \n3     4    21 NA          \n4     4    23 NA          \n5     5     9 NA          \n6     5    11 NA          \n7     6    11 NA          \n8     6    12 NA          \n9     7     3 NA          \n\n# adds multiple new column\norders_B %>%\n  mutate(satisfaction = NA,\n         numbers = 1:9)\n\n# A tibble: 9 × 4\n     id items satisfaction numbers\n  <dbl> <dbl> <lgl>          <int>\n1     2    10 NA                 1\n2     3    18 NA                 2\n3     4    21 NA                 3\n4     4    23 NA                 4\n5     5     9 NA                 5\n6     5    11 NA                 6\n7     6    11 NA                 7\n8     6    12 NA                 8\n9     7     3 NA                 9\n\n# have to assign back to tibble to update\norders_B <- orders_B %>%\n  mutate(satisfaction = NA,\n         numbers = 1:9)\n\norders_B %>%\n  mutate(numbers_as_strings = as.character(numbers))\n\n# A tibble: 9 × 5\n     id items satisfaction numbers numbers_as_strings\n  <dbl> <dbl> <lgl>          <int> <chr>             \n1     2    10 NA                 1 1                 \n2     3    18 NA                 2 2                 \n3     4    21 NA                 3 3                 \n4     4    23 NA                 4 4                 \n5     5     9 NA                 5 5                 \n6     5    11 NA                 6 6                 \n7     6    11 NA                 7 7                 \n8     6    12 NA                 8 8                 \n9     7     3 NA                 9 9                 \n\n# math operation on columns\norders_B %>%\n  mutate(items_minus_id = items - id)\n\n# A tibble: 9 × 5\n     id items satisfaction numbers items_minus_id\n  <dbl> <dbl> <lgl>          <int>          <dbl>\n1     2    10 NA                 1              8\n2     3    18 NA                 2             15\n3     4    21 NA                 3             17\n4     4    23 NA                 4             19\n5     5     9 NA                 5              4\n6     5    11 NA                 6              6\n7     6    11 NA                 7              5\n8     6    12 NA                 8              6\n9     7     3 NA                 9             -4"
  },
  {
    "objectID": "posts/week-8/index.html#dplyr-filter",
    "href": "posts/week-8/index.html#dplyr-filter",
    "title": "Week 8: Data Relations",
    "section": "Dplyr Filter",
    "text": "Dplyr Filter\n\nfull_data <- full_join(customers, orders, by = \"id\")\n\nWarning in full_join(customers, orders, by = \"id\"): Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 4 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning.\n\nfull_data\n\n# A tibble: 10 × 4\n      id city       postcode items\n   <dbl> <chr>      <chr>    <dbl>\n 1     1 Port Ellen PA42 7DU    NA\n 2     2 Dufftown   AB55 4DH    10\n 3     3 <NA>       <NA>        18\n 4     4 Aberlour   AB38 7RY    21\n 5     4 Aberlour   AB38 7RY    23\n 6     5 Tobermory  PA75 6NR     9\n 7     5 Tobermory  PA75 6NR    11\n 8     6 <NA>       <NA>        11\n 9     6 <NA>       <NA>        12\n10     7 <NA>       <NA>         3\n\n# if row have number greater than 10, filters\nfull_data %>%\n  filter(items > 10) # column name w/ logical comparison\n\n# A tibble: 6 × 4\n     id city      postcode items\n  <dbl> <chr>     <chr>    <dbl>\n1     3 <NA>      <NA>        18\n2     4 Aberlour  AB38 7RY    21\n3     4 Aberlour  AB38 7RY    23\n4     5 Tobermory PA75 6NR    11\n5     6 <NA>      <NA>        11\n6     6 <NA>      <NA>        12\n\nfull_data %>%\n  filter(postcode == \"AB38 7RY\")\n\n# A tibble: 2 × 4\n     id city     postcode items\n  <dbl> <chr>    <chr>    <dbl>\n1     4 Aberlour AB38 7RY    21\n2     4 Aberlour AB38 7RY    23\n\n# filter uses & to show both post code with items greater\nfull_data %>%\n  filter(postcode == \"AB38 7RY\" & items > 21)\n\n# A tibble: 1 × 4\n     id city     postcode items\n  <dbl> <chr>    <chr>    <dbl>\n1     4 Aberlour AB38 7RY    23"
  },
  {
    "objectID": "posts/week-9-data report/index.html#number-of-reviews-per-year",
    "href": "posts/week-9-data report/index.html#number-of-reviews-per-year",
    "title": "Video Game Review Report",
    "section": "Number of reviews per year",
    "text": "Number of reviews per year\nThe below histogram shows the number of video game reviews submitted to Amazon by year. From 1999 reviews largely increased year-on-year which is unsurprising given the growth of Amazon and access to the internet. The dataset shows the peak number of reviews was 2015 with a decline from 2016 to 2018. It is likely that this reflects the dataset being incomplete for recent years rather than the number of reviews declining in reality."
  },
  {
    "objectID": "posts/week-9-data report/index.html#verified-users",
    "href": "posts/week-9-data report/index.html#verified-users",
    "title": "Video Game Review Report",
    "section": "Verified users",
    "text": "Verified users\nThe dataset contains details of whether the review was based on a verified purchase. From Amazon Community:\n\nAn “Amazon Verified Purchase” review means that we’ve verified that the person writing the review purchased the product from Amazon, and didn’t receive the product at a big discount. Reviews that are not marked “Amazon Verified Purchase” are valuable as well, but, either we cannot confirm that the product was purchased from Amazon, or that the customer paid a price that is available to most Amazon shoppers.\n\nTable 1 shows the number of reviews based on verified and unverified purchases.\n\n\n\n\n\nverified\ncounts\n\n\n\n\nFALSE\n164932\n\n\nTRUE\n332645\n\n\n\n\n\nWhilst the number of verified reviews is substantially larger than the number of unverified reviews, the below histogram demonstrates that this has not been a consistent trend and that the large increase in the number of reviews is largely driven by an increase in verified reviews."
  },
  {
    "objectID": "posts/week-9-data report/index.html#overall",
    "href": "posts/week-9-data report/index.html#overall",
    "title": "Video Game Review Report",
    "section": "Overall",
    "text": "Overall\nAmazon review ratings are provided on a scale of 1 (worst) to 5 (best) stars. The histogram below shows the total number of reviews assigned each rating."
  },
  {
    "objectID": "posts/week-9-data report/index.html#by-purchase-status",
    "href": "posts/week-9-data report/index.html#by-purchase-status",
    "title": "Video Game Review Report",
    "section": "By purchase status",
    "text": "By purchase status\nHowever, if you break this data down by verified purchases status you can see that whilst the number of verified and unverified reviews with 1 to 4 star reviews are similar, there is a very large number of 5 star reviews for verified purchases compared to unverified purchases."
  },
  {
    "objectID": "posts/week-9-data report/index.html#by-purchase-status-1",
    "href": "posts/week-9-data report/index.html#by-purchase-status-1",
    "title": "Video Game Review Report",
    "section": "By purchase status",
    "text": "By purchase status\nAverage ratings for verified reviews were higher (both mean and median) than for unverified review, likely driven by the number of 5-star reviews for verified reviews.\n\n\n\n\n\nverified\nMean rating\nMedian rating\n\n\n\n\nFALSE\n3.91\n4\n\n\nTRUE\n4.37\n5"
  },
  {
    "objectID": "posts/week-9-data report/index.html#by-year-and-purchase-status",
    "href": "posts/week-9-data report/index.html#by-year-and-purchase-status",
    "title": "Video Game Review Report",
    "section": "By year and purchase status",
    "text": "By year and purchase status\nAverage ratings for verified purchases tended to increase over time, while average ratings for unverified purchases tended to decrease over time."
  }
]